{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/mikhailklemin/kinopoisks-movies-reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    result = []\n",
    "    files = os.listdir(path)\n",
    "    for f in files:\n",
    "        with open (f'{path}/{f}', \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read().replace('\\n', '')\n",
    "            result.append(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "negative_reviews = read_files('kinopoisk/neg')\n",
    "neutral_reviews = read_files('kinopoisk/neu')\n",
    "positive_reviews = read_files('kinopoisk/pos')\n",
    "\n",
    "negative_reviews_df = pd.DataFrame(data={'text': negative_reviews, 'sentiment': -1})\n",
    "neutral_reviews_df = pd.DataFrame(data={'text': neutral_reviews, 'sentiment': 0})\n",
    "positive_reviews_df = pd.DataFrame(data={'text': positive_reviews, 'sentiment': 1})\n",
    "\n",
    "reviews_df = negative_reviews_df.append(neutral_reviews_df).append(positive_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В 2003-ем году под руководством малоизвестного...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Грустно и печально. Грустно от того, что довол...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Давным-давно Кира Найтли ворвалась на экран от...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Я, в общем, ничего против уравновешенного феми...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Измена — один из сюжетов, который всегда будет...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  В 2003-ем году под руководством малоизвестного...         -1\n",
       "1  Грустно и печально. Грустно от того, что довол...         -1\n",
       "2  Давным-давно Кира Найтли ворвалась на экран от...         -1\n",
       "3  Я, в общем, ничего против уравновешенного феми...         -1\n",
       "4  Измена — один из сюжетов, который всегда будет...         -1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/c/sentiment-analysis-in-russian/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('russian_news.json', \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "\n",
    "json_data = json.loads(data)\n",
    "news_df = pd.DataFrame(json_data)\n",
    "\n",
    "def reformat_sentiment(sentiment):\n",
    "    if sentiment == 'negative':\n",
    "        return -1\n",
    "    if sentiment == 'positive':\n",
    "        return 1\n",
    "    if sentiment == 'neutral':\n",
    "        return 0\n",
    "    \n",
    "    return None\n",
    "\n",
    "news_df['sentiment'] = news_df['sentiment'].apply(reformat_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Досудебное расследование по факту покупки ЕНПФ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Медики рассказали о состоянии пострадавшего му...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Прошел почти год, как железнодорожным оператор...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>По итогам 12 месяцев 2016 года на территории р...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Астана. 21 ноября. Kazakhstan Today - Агентств...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  Досудебное расследование по факту покупки ЕНПФ...         -1\n",
       "1  Медики рассказали о состоянии пострадавшего му...         -1\n",
       "2  Прошел почти год, как железнодорожным оператор...         -1\n",
       "3  По итогам 12 месяцев 2016 года на территории р...         -1\n",
       "4  Астана. 21 ноября. Kazakhstan Today - Агентств...         -1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = news_df[['text', 'sentiment']]\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/sismetanin/rureviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_clothing_df = pd.read_csv('rureviews.csv', encoding='UTF-8', sep='\\t')\n",
    "\n",
    "def reformat_sentiment_with_typo(sentiment):\n",
    "    if sentiment == 'negative':\n",
    "        return -1\n",
    "    if sentiment == 'positive':\n",
    "        return 1\n",
    "    if sentiment == 'neautral':\n",
    "        return 0\n",
    "    \n",
    "    return None\n",
    "\n",
    "women_clothing_df['sentiment'] = women_clothing_df['sentiment'].apply(reformat_sentiment_with_typo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_clothing_df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  качество плохое пошив ужасный (горловина напер...         -1\n",
       "1  Товар отдали другому человеку, я не получила п...         -1\n",
       "2  Ужасная синтетика! Тонкая, ничего общего с пре...         -1\n",
       "3  товар не пришел, продавец продлил защиту без м...         -1\n",
       "4      Кофточка голая синтетика, носить не возможно.         -1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_clothing_df.columns = ['text', 'sentiment']\n",
    "women_clothing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rusentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusentiment_df1 = pd.read_csv('rusentiment/rusentiment_preselected_posts.csv')\n",
    "rusentiment_df2 = pd.read_csv('rusentiment/rusentiment_random_posts.csv')\n",
    "rusentiment_df3 = pd.read_csv('rusentiment/rusentiment_test.csv')\n",
    "\n",
    "rusentiment_df = rusentiment_df1.append(rusentiment_df2).append(rusentiment_df3)\n",
    "rusentiment_df['sentiment'] = rusentiment_df['label'].apply(reformat_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -1., nan,  1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusentiment_df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Прорвём информационную блокаду изнутри.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Никогда у меня не будет \"одного приложения для...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Кури-и тебя не укусит злая собака, потому что ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Есть 3 типа людей:\\nУмные, которые делают все ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>мегафон чет накрыло</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0           Прорвём информационную блокаду изнутри.         0.0\n",
       "1  Никогда у меня не будет \"одного приложения для...       -1.0\n",
       "2  Кури-и тебя не укусит злая собака, потому что ...        NaN\n",
       "3  Есть 3 типа людей:\\nУмные, которые делают все ...        0.0\n",
       "4                                мегафон чет накрыло        0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusentiment_df = rusentiment_df[['text', 'sentiment']]\n",
    "rusentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединенный dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В 2003-ем году под руководством малоизвестного...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Грустно и печально. Грустно от того, что довол...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Давным-давно Кира Найтли ворвалась на экран от...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Я, в общем, ничего против уравновешенного феми...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Измена — один из сюжетов, который всегда будет...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  В 2003-ем году под руководством малоизвестного...       -1.0\n",
       "1  Грустно и печально. Грустно от того, что довол...       -1.0\n",
       "2  Давным-давно Кира Найтли ворвалась на экран от...       -1.0\n",
       "3  Я, в общем, ничего против уравновешенного феми...       -1.0\n",
       "4  Измена — один из сюжетов, который всегда будет...       -1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dfs = [reviews_df, news_df, women_clothing_df, rusentiment_df]    \n",
    "total_df = reduce(lambda left, right: left.append(right), total_dfs)\n",
    "\n",
    "total_df = total_df[total_df['sentiment'].notnull()]\n",
    "total_df = total_df[total_df['text'].notnull()]\n",
    "\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv('total.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['word_count'] = total_df['text'].apply(lambda x: len([word for word in x.split(' ')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упрощенная предобработка текста\n",
    "\n",
    "1. Заменить знаки препинания \\n на пробелы\n",
    "2. Убрать заведомо \"бракованные\" примеры - слова с длиной более чем 35 символов (максимальная длина слова в русском языке)\n",
    "3. Убрать все символы кроме русских букв\n",
    "4. Убрать стоп-слова\n",
    "\n",
    "### Дополнительная обработка (специфичная для текущего набора данных)\n",
    "\n",
    "* Разбить рускоязычные хэштеги на слова\n",
    "* Заменить смайлики на оцениваемые слова\n",
    "* * Предварительно убрать парные скобки\n",
    "* \"Схлопнуть\" дублирующиеся буквы: \"отлииииииично\" -> \"отлично\"\n",
    "* Заменить очевидные оценки на оцениваемые слова: \"10 из 10\" -> \"отличный\"\n",
    "\n",
    "### Обязательная обработка после балансировки набора данных\n",
    "* Стеммизация/лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['а', 'без', 'более', 'больше', 'будет', 'будто', 'бы', 'был', 'была', 'были', 'было', 'быть', 'в', 'вам', 'вас', 'вдруг', 'ведь', 'во', 'вот', 'впрочем', 'все', 'всегда', 'всего', 'всех', 'всю', 'вы', 'где', 'да', 'даже', 'два', 'для', 'до', 'другой', 'его', 'ее', 'ей', 'ему', 'если', 'есть', 'еще', 'ж', 'же', 'за', 'зачем', 'здесь', 'и', 'из', 'или', 'им', 'иногда', 'их', 'к', 'как', 'какая', 'какой', 'когда', 'конечно', 'кто', 'куда', 'ли', 'лучше', 'между', 'меня', 'мне', 'много', 'может', 'можно', 'мой', 'моя', 'мы', 'на', 'над', 'надо', 'наконец', 'нас', 'него', 'нее', 'ней', 'нельзя', 'ни', 'нибудь', 'никогда', 'ним', 'них', 'ничего', 'но', 'ну', 'о', 'об', 'один', 'он', 'она', 'они', 'опять', 'от', 'перед', 'по', 'под', 'после', 'потом', 'потому', 'почти', 'при', 'про', 'раз', 'разве', 'с', 'сам', 'свою', 'себе', 'себя', 'сейчас', 'со', 'совсем', 'так', 'такой', 'там', 'тебя', 'тем', 'теперь', 'то', 'тогда', 'того', 'тоже', 'только', 'том', 'тот', 'три', 'тут', 'ты', 'у', 'уж', 'уже', 'хорошо', 'хоть', 'чего', 'чем', 'через', 'что', 'чтоб', 'чтобы', 'чуть', 'эти', 'этого', 'этой', 'этом', 'этот', 'эту', 'я']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dmitry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dmitry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "russian_stopwords.remove('не')\n",
    "russian_stopwords.remove('нет')\n",
    "\n",
    "russian_stopwords.sort()\n",
    "print(russian_stopwords)\n",
    "russian_stopwords = set(russian_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "positive = ' радость '\n",
    "negative = ' грусть '\n",
    "\n",
    "def split_hash_tag(row):\n",
    "    match = re.search(r\"#([А-Яа-я]+)\", row)\n",
    "    if match and match.group(1):\n",
    "        replacements = ' '.join(re.findall('[А-Я][^А-Я]*', match.group(1)))\n",
    "        return row.replace(match.group(0), replacements)\n",
    "    \n",
    "    return row\n",
    "\n",
    "def remove_parenthesis_pairs(row):\n",
    "    row = re.sub(r'((\\(|\\[|\\{)(.*)(\\)|\\]|\\}))', '\\g<2>', row)\n",
    "    return row\n",
    "\n",
    "def replace_smiles(row):    \n",
    "    row = re.sub(r'((:|;|=|8)?(-|%|5|c|с)?(\\)|\\]|\\}|3)+|😜|😄|😂|💋|♥)', positive, row)\n",
    "    row = re.sub(r'((:|;|=|8)(-|%|5|c|с)?(d|p|\\*)+)', positive, row)\n",
    "    \n",
    "    row = re.sub(r'((:|;|=|8)?\\'?(-|%|5|c|с)?(\\(|\\[|\\{)+)', negative, row)\n",
    "    row = re.sub(r'((:|;|=|8)\\'?(-|%|5|c|с)?(g|o)+)', negative, row)\n",
    "    \n",
    "    return row\n",
    "\n",
    "def replace_obvious_scores(row):\n",
    "    row = re.sub(r'([7-9]|1[0-9]) из 10', positive, row)\n",
    "    row = re.sub(r'[0-4] из 10', negative, row)\n",
    "    return row\n",
    "\n",
    "def collapse_same_letters(row):\n",
    "    row = re.sub(r'([а-яё])\\1{2,}', '\\g<1>', row)\n",
    "    return row\n",
    "\n",
    "def remove_stop_words(row):\n",
    "    words = row.split(' ')\n",
    "    row = ' '.join([word for word in words if word not in russian_stopwords])\n",
    "    return row\n",
    "\n",
    "def preprocessing(row):\n",
    "    row = split_hash_tag(row)\n",
    "    row = row.lower()\n",
    "    row = row.replace('\\n', ' ')\n",
    "    row = row.replace('ё', 'е')\n",
    "    \n",
    "    row = remove_parenthesis_pairs(row)\n",
    "    row = replace_smiles(row)\n",
    "    row = replace_obvious_scores(row)\n",
    "    row = collapse_same_letters(row)\n",
    "    \n",
    "    row = remove_stop_words(row)\n",
    "        \n",
    "    row = re.sub(r\"[^а-я ]\", \" \", row)\n",
    "    row = re.sub(r\"[а-я]{35,}\", \"\", row)\n",
    "    row = re.sub(r\" {2,}\", \" \", row)\n",
    "    row = row.strip()                   \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253210/253210 [02:22<00:00, 1775.09it/s] \n",
      "100%|██████████| 253210/253210 [00:03<00:00, 73713.89it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В 2003-ем году под руководством малоизвестного...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>отличный ем году руководством малоизвестного р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Грустно и печально. Грустно от того, что довол...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>249</td>\n",
       "      <td>грустно печально грустно того довольно неплохо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Давным-давно Кира Найтли ворвалась на экран от...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>241</td>\n",
       "      <td>давным давно кира найтли ворвалась экран отваж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Я, в общем, ничего против уравновешенного феми...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>195</td>\n",
       "      <td>я общем против уравновешенного феминизма не им...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Измена — один из сюжетов, который всегда будет...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>201</td>\n",
       "      <td>измена сюжетов который вызывать интерес зрител...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  word_count  \\\n",
       "0  В 2003-ем году под руководством малоизвестного...       -1.0          26   \n",
       "1  Грустно и печально. Грустно от того, что довол...       -1.0         249   \n",
       "2  Давным-давно Кира Найтли ворвалась на экран от...       -1.0         241   \n",
       "3  Я, в общем, ничего против уравновешенного феми...       -1.0         195   \n",
       "4  Измена — один из сюжетов, который всегда будет...       -1.0         201   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  отличный ем году руководством малоизвестного р...  \n",
       "1  грустно печально грустно того довольно неплохо...  \n",
       "2  давным давно кира найтли ворвалась экран отваж...  \n",
       "3  я общем против уравновешенного феминизма не им...  \n",
       "4  измена сюжетов который вызывать интерес зрител...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['preprocessed'] = total_df['text'].progress_apply(preprocessing)\n",
    "total_df['word_count'] = total_df['preprocessed'].progress_apply(lambda x: len([word for word in x.split(' ') if word is not '']))\n",
    "\n",
    "total_df = total_df[(total_df['word_count'] > 0)]\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ качества данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>251950.000000</td>\n",
       "      <td>251950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.283024</td>\n",
       "      <td>109.404108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.798686</td>\n",
       "      <td>132.979737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4971.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentiment     word_count\n",
       "count  251950.000000  251950.000000\n",
       "mean        0.283024     109.404108\n",
       "std         0.798686     132.979737\n",
       "min        -1.000000       1.000000\n",
       "25%         0.000000      11.000000\n",
       "50%         1.000000      63.000000\n",
       "75%         1.000000     169.000000\n",
       "max         1.000000    4971.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.186806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>0.186806</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentiment  word_count\n",
       "sentiment    1.000000    0.186806\n",
       "word_count   0.186806    1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавимся от сверх-длинных записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>231571.000000</td>\n",
       "      <td>231571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.264036</td>\n",
       "      <td>81.348709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.800783</td>\n",
       "      <td>83.132365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>142.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentiment     word_count\n",
       "count  231571.000000  231571.000000\n",
       "mean        0.264036      81.348709\n",
       "std         0.800783      83.132365\n",
       "min        -1.000000       1.000000\n",
       "25%         0.000000      10.000000\n",
       "50%         0.000000      44.000000\n",
       "75%         1.000000     142.000000\n",
       "max         1.000000     299.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = total_df[total_df['word_count'] < 300]\n",
    "total_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    112891\n",
       " 0.0     66932\n",
       "-1.0     51748\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как нейтральные высказывания в абсолютном меньшинстве, будем отталкиваться от их числа при формировании финального датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>66932.0</td>\n",
       "      <td>66932.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>59.782376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>76.368872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment    word_count\n",
       "count    66932.0  66932.000000\n",
       "mean         0.0     59.782376\n",
       "std          0.0     76.368872\n",
       "min          0.0      1.000000\n",
       "25%          0.0      6.000000\n",
       "50%          0.0     17.000000\n",
       "75%          0.0    101.000000\n",
       "max          0.0    299.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_sentiment_df = total_df[total_df['sentiment'] == 0]\n",
    "neutral_sentiment_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neutral_sentiment_df['word_count'].hist(bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для балансировки можно сгруппировать по количеству слов диапазонами по 5 и взять из каждой группы по одинаковому количеству записей для каждого класса\n",
    "\n",
    "### Для ускорения процесса искусственно ограничимся примерами до 100 слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word_count = 100\n",
    "step = 5\n",
    "max_word_count_rounded = max_word_count - max_word_count % step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>wc_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>146573.000000</td>\n",
       "      <td>146573.000000</td>\n",
       "      <td>146573.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.129731</td>\n",
       "      <td>25.381660</td>\n",
       "      <td>4.670615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.801006</td>\n",
       "      <td>26.958083</td>\n",
       "      <td>5.397209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentiment     word_count       wc_group\n",
       "count  146573.000000  146573.000000  146573.000000\n",
       "mean        0.129731      25.381660       4.670615\n",
       "std         0.801006      26.958083       5.397209\n",
       "min        -1.000000       1.000000       0.000000\n",
       "25%        -1.000000       6.000000       1.000000\n",
       "50%         0.000000      13.000000       2.000000\n",
       "75%         1.000000      35.000000       7.000000\n",
       "max         1.000000      99.000000      19.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = total_df[total_df['word_count'] < max_word_count_rounded]\n",
    "total_df['wc_group'] = total_df['word_count'].apply(lambda x: int(x / step))\n",
    "total_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>wc_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.158670</td>\n",
       "      <td>0.157981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>0.158670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wc_group</th>\n",
       "      <td>0.157981</td>\n",
       "      <td>0.998664</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentiment  word_count  wc_group\n",
       "sentiment    1.000000    0.158670  0.157981\n",
       "word_count   0.158670    1.000000  0.998664\n",
       "wc_group     0.157981    0.998664  1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sentiment_df = total_df[total_df['sentiment'] ==  1]\n",
    "neutral_sentiment_df =  total_df[total_df['sentiment'] ==  0]\n",
    "negative_sentiment_df = total_df[total_df['sentiment'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8137</td>\n",
       "      <td>10942</td>\n",
       "      <td>3801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11064</td>\n",
       "      <td>12873</td>\n",
       "      <td>10023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7118</td>\n",
       "      <td>7145</td>\n",
       "      <td>7086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4438</td>\n",
       "      <td>4173</td>\n",
       "      <td>4281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2880</td>\n",
       "      <td>2634</td>\n",
       "      <td>2731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2044</td>\n",
       "      <td>1846</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1605</td>\n",
       "      <td>1440</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1425</td>\n",
       "      <td>1078</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1346</td>\n",
       "      <td>880</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1233</td>\n",
       "      <td>795</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1302</td>\n",
       "      <td>736</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1386</td>\n",
       "      <td>641</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1421</td>\n",
       "      <td>623</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1501</td>\n",
       "      <td>580</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1645</td>\n",
       "      <td>621</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1772</td>\n",
       "      <td>612</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1767</td>\n",
       "      <td>603</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1870</td>\n",
       "      <td>623</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1888</td>\n",
       "      <td>608</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1920</td>\n",
       "      <td>611</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    positive  neutral  negative\n",
       "0       8137    10942      3801\n",
       "1      11064    12873     10023\n",
       "2       7118     7145      7086\n",
       "3       4438     4173      4281\n",
       "4       2880     2634      2731\n",
       "5       2044     1846      1892\n",
       "6       1605     1440      1373\n",
       "7       1425     1078      1040\n",
       "8       1346      880       797\n",
       "9       1233      795       694\n",
       "10      1302      736       589\n",
       "11      1386      641       571\n",
       "12      1421      623       460\n",
       "13      1501      580       511\n",
       "14      1645      621       459\n",
       "15      1772      612       483\n",
       "16      1767      603       472\n",
       "17      1870      623       473\n",
       "18      1888      608       496\n",
       "19      1920      611       515"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_stats = positive_sentiment_df['wc_group'].value_counts(sort=False).to_frame()\n",
    "neutral_stats = neutral_sentiment_df['wc_group'].value_counts(sort=False).to_frame()\n",
    "negative_stats = negative_sentiment_df['wc_group'].value_counts(sort=False).to_frame()\n",
    "\n",
    "stats = [positive_stats, neutral_stats, negative_stats]\n",
    "stats_df = reduce(lambda left, right: pd.merge(left, right, left_index=True, right_index=True), stats)\n",
    "stats_df.columns = ['positive', 'neutral', 'negative']\n",
    "\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы и ограничения\n",
    "Для равномерности распределения по классам и длительности текста необходимо из каждой группы от 0 (1-5 слов) по 19 (95-100 слов) брать по одинаковому количеству примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>wc_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19810</th>\n",
       "      <td>Герои детства!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>герои детства</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15238</th>\n",
       "      <td>ШиКаРна БаБа=»»</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>шикарна баба</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68559</th>\n",
       "      <td>Всё отлично.супер платье.советую</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>отлично супер платье советую</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>хочу дождь!!!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>хочу дождь</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78819</th>\n",
       "      <td>пришло быстро, норм</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>пришло быстро норм</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  sentiment  word_count  \\\n",
       "19810                     Герои детства!        1.0           2   \n",
       "15238                    ШиКаРна БаБа=»»        1.0           2   \n",
       "68559  Всё отлично.супер платье.советую         1.0           4   \n",
       "1980                       хочу дождь!!!        1.0           2   \n",
       "78819                пришло быстро, норм        1.0           3   \n",
       "\n",
       "                       preprocessed  wc_group  \n",
       "19810                 герои детства         0  \n",
       "15238                  шикарна баба         0  \n",
       "68559  отлично супер платье советую         0  \n",
       "1980                     хочу дождь         0  \n",
       "78819            пришло быстро норм         0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [positive_sentiment_df, neutral_sentiment_df, negative_sentiment_df]\n",
    "\n",
    "result_dfs = []\n",
    "for df in dfs:\n",
    "    restricted_df = df[df['word_count'] < max_word_count]\n",
    "    for name, group in restricted_df.groupby('wc_group'):\n",
    "        n_samples = stats_df.loc[int(name)].min()        \n",
    "        sampled_df = group.sample(n=n_samples)\n",
    "        \n",
    "        result_dfs.append(sampled_df)\n",
    "        \n",
    "balanced_df = reduce(lambda left, right: left.append(right), result_dfs)\n",
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>wc_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>115488.0000</td>\n",
       "      <td>115488.000000</td>\n",
       "      <td>115488.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>22.343992</td>\n",
       "      <td>4.076553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.8165</td>\n",
       "      <td>23.024631</td>\n",
       "      <td>4.602538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.0000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment     word_count       wc_group\n",
       "count  115488.0000  115488.000000  115488.000000\n",
       "mean        0.0000      22.343992       4.076553\n",
       "std         0.8165      23.024631       4.602538\n",
       "min        -1.0000       1.000000       0.000000\n",
       "25%        -1.0000       7.000000       1.000000\n",
       "50%         0.0000      13.000000       2.000000\n",
       "75%         1.0000      27.000000       5.000000\n",
       "max         1.0000      99.000000      19.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>wc_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>1.025710e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>-6.125896e-04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.981473e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wc_group</th>\n",
       "      <td>1.025710e-17</td>\n",
       "      <td>0.998147</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sentiment  word_count      wc_group\n",
       "sentiment   1.000000e+00   -0.000613  1.025710e-17\n",
       "word_count -6.125896e-04    1.000000  9.981473e-01\n",
       "wc_group    1.025710e-17    0.998147  1.000000e+00"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "В полученном датасете равное распределение примеров для каждого класса, для разных длин входных данных; явных ошибочных корреляций не наблюдается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация финального набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('ru_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115488/115488 [25:37<00:00, 75.11it/s] \n"
     ]
    }
   ],
   "source": [
    "balanced_df['preprocessed'] = balanced_df['preprocessed'].progress_apply(lambda row: ' '.join([w.lemma_ for w in nlp(row)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>wc_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19810</th>\n",
       "      <td>Герои детства!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>герой детство</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15238</th>\n",
       "      <td>ШиКаРна БаБа=»»</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>шикарный баба</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68559</th>\n",
       "      <td>Всё отлично.супер платье.советую</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>отлично супер платье советую</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>хочу дождь!!!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>хотеть дождь</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78819</th>\n",
       "      <td>пришло быстро, норм</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>прийти быстро норма</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  sentiment  word_count  \\\n",
       "19810                     Герои детства!        1.0           2   \n",
       "15238                    ШиКаРна БаБа=»»        1.0           2   \n",
       "68559  Всё отлично.супер платье.советую         1.0           4   \n",
       "1980                       хочу дождь!!!        1.0           2   \n",
       "78819                пришло быстро, норм        1.0           3   \n",
       "\n",
       "                       preprocessed  wc_group  \n",
       "19810                 герой детство         0  \n",
       "15238                 шикарный баба         0  \n",
       "68559  отлично супер платье советую         0  \n",
       "1980                   хотеть дождь         0  \n",
       "78819           прийти быстро норма         0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115488/115488 [00:00<00:00, 285149.36it/s]\n"
     ]
    }
   ],
   "source": [
    "balanced_df['word_count'] = balanced_df['preprocessed'].progress_apply(lambda x: len([word for word in x.split(' ')]))\n",
    "balanced_df = balanced_df[balanced_df['word_count'] <= max_word_count]\n",
    "balanced_df.to_csv('preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.read_csv('preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных для нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для анализа эмоционального окраса (sentiment analysis) для ускорения процесса обучения сети можно применить претренированный слой эмбеддингов (embeddings layer).\n",
    "В данном случае принимаю решение использовать эмбеддинги \"подслов\" (subwords) от BPEmb (ru.wiki.bpe.vs100000.d100.w2v).\n",
    "\n",
    "Использование \"подслов\" серьезно сокращает вероятность встретить незнакомые (out-of-vocabulary) слова, плюс ограниченный набор упрощает дотренировку слоя эмбеддингов (fine-tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "from pathlib import Path\n",
    "bpemb = BPEmb(lang='ru', cache_dir=Path('./'), dim=100, vs=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0617559979cc40bd92b228b1ac20e0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=100001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import mmap\n",
    "import re\n",
    "\n",
    "embeddings_path = 'ru/ru.wiki.bpe.vs100000.d100.w2v.txt'\n",
    "\n",
    "def get_num_lines(file_path):\n",
    "    fp = open(file_path, \"r+\")\n",
    "    buf = mmap.mmap(fp.fileno(), 0)\n",
    "    lines = 0\n",
    "    while buf.readline():\n",
    "        lines += 1\n",
    "    return lines\n",
    "\n",
    "embeddings_dict = {}\n",
    "with open(embeddings_path, 'r', encoding='utf-8') as file:\n",
    "    for line in tqdm_notebook(file, total=get_num_lines(embeddings_path)):\n",
    "        values = line.split()\n",
    "        word = values[0].lower()\n",
    "        if word in embeddings_dict:\n",
    "            continue\n",
    "        \n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наведение порядка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>wc_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19810</td>\n",
       "      <td>Герои детства!</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>герой детство</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15238</td>\n",
       "      <td>ШиКаРна БаБа=»»</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>шикарный баба</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68559</td>\n",
       "      <td>Всё отлично.супер платье.советую</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>отлично супер платье советую</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980</td>\n",
       "      <td>хочу дождь!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>хотеть дождь</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78819</td>\n",
       "      <td>пришло быстро, норм</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>прийти быстро норма</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                               text  sentiment  word_count  \\\n",
       "0       19810                     Герои детства!          1           2   \n",
       "1       15238                    ШиКаРна БаБа=»»          1           2   \n",
       "2       68559  Всё отлично.супер платье.советую           1           4   \n",
       "3        1980                      хочу дождь!!!          1           2   \n",
       "4       78819                пришло быстро, норм          1           3   \n",
       "\n",
       "                   preprocessed  wc_group  \n",
       "0                 герой детство         0  \n",
       "1                 шикарный баба         0  \n",
       "2  отлично супер платье советую         0  \n",
       "3                  хотеть дождь         0  \n",
       "4           прийти быстро норма         0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = balanced_df[balanced_df['preprocessed'].notnull()]\n",
    "df['sentiment']=df['sentiment'].astype('int32')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка последовательностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e8e81600bc47fb8f356d5a3b406bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=99998.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3997/115488 [00:00<00:02, 39573.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115488/115488 [00:13<00:00, 8296.40it/s] \n",
      "100%|██████████| 115488/115488 [00:00<00:00, 807600.95it/s]\n",
      "100%|██████████| 115488/115488 [00:02<00:00, 47467.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(len(embeddings_dict.keys()))\n",
    "tokenizer.fit_on_texts(tqdm_notebook(embeddings_dict.keys()))\n",
    "\n",
    "df['sequences'] = df['preprocessed'].progress_apply(lambda x: tokenizer.texts_to_sequences([bpemb.encode(x)])[0])\n",
    "df['seq_length'] = df['sequences'].progress_apply(lambda x: len(x))\n",
    "\n",
    "max_sequence_length = df['seq_length'].max()\n",
    "df['padded_sequences'] = df['sequences'].progress_apply(lambda x: pad_sequences([x], max_sequence_length)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в слое эмбеддингов нет слов, использованных в тексте, колонка 'sequences' будет пустой. Исключим такие примеры из набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['seq_length'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для слоя эмбеддингов не потребуется категоризация, но для лейблов она необходима (note: если не использовать sparse_categorical_loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 0: 1, -1: 2}\n"
     ]
    }
   ],
   "source": [
    "allowed_outputs = list(df['sentiment'].unique())\n",
    "outputs_index = {x:i for i, x in enumerate(allowed_outputs)}\n",
    "print(outputs_index)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "df[f'output'] = df[f'sentiment'].apply(lambda x: outputs_index[x]) \n",
    "df[f'output'] = df[f'output'].apply(lambda x: to_categorical(x, num_classes=len(outputs_index)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df[['text', 'sentiment', 'preprocessed', 'sequences', 'seq_length', 'padded_sequences', 'output']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>sequences</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>padded_sequences</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Герои детства!</td>\n",
       "      <td>1</td>\n",
       "      <td>герой детство</td>\n",
       "      <td>[2498, 18198]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ШиКаРна БаБа=»»</td>\n",
       "      <td>1</td>\n",
       "      <td>шикарный баба</td>\n",
       "      <td>[87598, 252, 18093]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Всё отлично.супер платье.советую</td>\n",
       "      <td>1</td>\n",
       "      <td>отлично супер платье советую</td>\n",
       "      <td>[26931, 4248, 28121, 3130, 5051]</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>хочу дождь!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>хотеть дождь</td>\n",
       "      <td>[17312, 190, 26222]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>пришло быстро, норм</td>\n",
       "      <td>1</td>\n",
       "      <td>прийти быстро норма</td>\n",
       "      <td>[29505, 3837, 4998]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text  sentiment                  preprocessed  \\\n",
       "0                     Герои детства!          1                 герой детство   \n",
       "1                    ШиКаРна БаБа=»»          1                 шикарный баба   \n",
       "2  Всё отлично.супер платье.советую           1  отлично супер платье советую   \n",
       "3                      хочу дождь!!!          1                  хотеть дождь   \n",
       "4                пришло быстро, норм          1           прийти быстро норма   \n",
       "\n",
       "                          sequences  seq_length  \\\n",
       "0                     [2498, 18198]           2   \n",
       "1               [87598, 252, 18093]           3   \n",
       "2  [26931, 4248, 28121, 3130, 5051]           5   \n",
       "3               [17312, 190, 26222]           3   \n",
       "4               [29505, 3837, 4998]           3   \n",
       "\n",
       "                                    padded_sequences           output  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [1.0, 0.0, 0.0]  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [1.0, 0.0, 0.0]  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [1.0, 0.0, 0.0]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [1.0, 0.0, 0.0]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [1.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('postprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка тренировочного, валидационного и тестового наборов данных\n",
    "Для упрощения анализа возможных ошибок также сбалансирую классы для этих подсетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "positive_sentiment_df = df[df['sentiment'] == 1]\n",
    "neutral_sentiment_df = df[df['sentiment'] == 0]\n",
    "negative_sentiment_df = df[df['sentiment'] == -1]\n",
    "\n",
    "def split_dataframe(dataframe):\n",
    "    test = dataframe.sample(n=1000)\n",
    "    validation = dataframe.loc[~dataframe.index.isin(test.index)].sample(n=3000)\n",
    "    train = dataframe.loc[(~dataframe.index.isin(validation.index)) & (~dataframe.index.isin(test.index))].sample(frac=1)\n",
    "    \n",
    "    return (train, validation, test)\n",
    "\n",
    "positive_split = split_dataframe(positive_sentiment_df)\n",
    "neutral_split = split_dataframe(neutral_sentiment_df)\n",
    "negative_split = split_dataframe(negative_sentiment_df)\n",
    "\n",
    "train = positive_split[0].append(neutral_split[0]).append(negative_split[0])\n",
    "validation = positive_split[1].append(neutral_split[1]).append(negative_split[1])\n",
    "test = positive_split[2].append(neutral_split[2]).append(negative_split[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103488, 188) (103488, 3)\n",
      "(9000, 188) (9000, 3)\n",
      "(3000, 188) (3000, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_arrayed_data(df_set):\n",
    "    setX = np.stack(df_set['padded_sequences'].values, axis=0)\n",
    "    setY = np.stack(df_set['output'].values, axis=0)\n",
    "        \n",
    "    return (setX, setY)\n",
    "\n",
    "trainX, trainY = get_arrayed_data(train)\n",
    "validationX, validationY = get_arrayed_data(validation)\n",
    "testX, testY = get_arrayed_data(test)\n",
    "\n",
    "\n",
    "print(trainX.shape, trainY.shape)\n",
    "print(validationX.shape, validationY.shape)\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняю некоторые данные, необходимые для дальнейшего standalone функционирования нейросети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('model/input-map.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer.word_index, ensure_ascii=False))\n",
    "    \n",
    "with open('model/input-sequence-length.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(int(max_sequence_length), ensure_ascii=False))\n",
    "    \n",
    "one_hot_map = {int(v): int(k) for k, v in outputs_index.items()}\n",
    "with open('model/output-map.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(one_hot_map, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history, title=''):\n",
    "    colors = ['r', 'g', 'b', 'k']\n",
    "    metrics= ['f1', 'precision', 'recall', 'acc']\n",
    "    \n",
    "    x = range(1, len(history['acc']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.ylim(0, 1.1)\n",
    "    for i, name in enumerate(metrics):\n",
    "        plt.plot(x, history[name], colors[i], label=name) \n",
    "    plt.title(f'Training {title}')\n",
    "    plt.legend()\n",
    "        \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.ylim(0, 1.1)\n",
    "    for i, name in enumerate(metrics):\n",
    "        name = f'val_{name}'\n",
    "        plt.plot(x, history[name], colors[i], label=name)\n",
    "    plt.title(f'Validation {title}')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98740"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_count = len(tokenizer.word_index) + 1\n",
    "token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall_value = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall_value\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision_value = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision_value\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    precision_value = precision(y_true, y_pred)\n",
    "    recall_value = recall(y_true, y_pred)\n",
    "    return 2*((precision_value*recall_value)/(precision_value+recall_value+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эмпирическим путем было определено, что без fine-tuning'а слоя эмбеддингов не обойтись"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7369f52006457aba61b09c5c648e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=98739.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))\n",
    "for word, i in tqdm_notebook(tokenizer.word_index.items()):\n",
    "    if word in embeddings_dict:\n",
    "        embedding_matrix[i] = embeddings_dict[word]\n",
    "        \n",
    "embedding_layer = Embedding(len(tokenizer.word_index) + 1, 100,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_sequence_length,\n",
    "                    embeddings_regularizer=regularizers.l2(0.001),\n",
    "                    trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((max_sequence_length,))\n",
    "x = embedding_layer(inp)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu',\n",
    "           kernel_regularizer=regularizers.l1(0.001),\n",
    "           bias_regularizer=regularizers.l1(0.001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling1D(pool_size=2)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "x = LSTM(64, activity_regularizer=regularizers.l1(0.0001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "out = Dense(trainY.shape[1], activation='softmax')(x)\n",
    "model = Model(inp, out)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', f1, precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 188)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 188, 100)          9874000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 188, 100)          400       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 188, 64)           19264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 188, 64)           256       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 94, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 94, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 9,927,395\n",
      "Trainable params: 9,926,939\n",
      "Non-trainable params: 456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 103488 samples, validate on 9000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103488/103488 [==============================] - 105s 1ms/sample - loss: 1500.6793 - acc: 0.6330 - f1: 0.6084 - precision: 0.6765 - recall: 0.5538 - val_loss: 997.1182 - val_acc: 0.6313 - val_f1: 0.6126 - val_precision: 0.6577 - val_recall: 0.5745\n",
      "Epoch 2/50\n",
      "103488/103488 [==============================] - 104s 1ms/sample - loss: 960.0840 - acc: 0.6841 - f1: 0.6661 - precision: 0.7210 - recall: 0.6198 - val_loss: 938.1407 - val_acc: 0.6836 - val_f1: 0.6693 - val_precision: 0.7190 - val_recall: 0.6270\n",
      "Epoch 3/50\n",
      "103488/103488 [==============================] - 104s 1ms/sample - loss: 922.2608 - acc: 0.7025 - f1: 0.6890 - precision: 0.7351 - recall: 0.6491 - val_loss: 906.7533 - val_acc: 0.6992 - val_f1: 0.6903 - val_precision: 0.7211 - val_recall: 0.66244 - precisio\n",
      "Epoch 4/50\n",
      "103488/103488 [==============================] - 102s 989us/sample - loss: 891.5760 - acc: 0.7150 - f1: 0.7039 - precision: 0.7442 - recall: 0.6683 - val_loss: 876.4583 - val_acc: 0.7004 - val_f1: 0.6920 - val_precision: 0.7245 - val_recall: 0.6629\n",
      "Epoch 5/50\n",
      "103488/103488 [==============================] - 103s 997us/sample - loss: 861.5261 - acc: 0.7237 - f1: 0.7142 - precision: 0.7502 - recall: 0.6821 - val_loss: 846.6840 - val_acc: 0.7047 - val_f1: 0.6928 - val_precision: 0.7296 - val_recall: 0.6603\n",
      "Epoch 6/50\n",
      "103424/103488 [============================>.] - ETA: 0s - loss: 832.0227 - acc: 0.7330 - f1: 0.7233 - precision: 0.7580 - recall: 0.6922- ETA: 4s - loss: 832\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "103488/103488 [==============================] - 103s 992us/sample - loss: 832.0137 - acc: 0.7329 - f1: 0.7233 - precision: 0.7580 - recall: 0.6922 - val_loss: 817.4406 - val_acc: 0.7022 - val_f1: 0.6905 - val_precision: 0.7237 - val_recall: 0.6607\n",
      "Epoch 7/50\n",
      "103488/103488 [==============================] - 102s 986us/sample - loss: 814.3842 - acc: 0.7733 - f1: 0.7677 - precision: 0.7918 - recall: 0.7454 - val_loss: 811.6227 - val_acc: 0.7083 - val_f1: 0.7019 - val_precision: 0.7225 - val_recall: 0.6828oss: 814.4434 - acc: 0.7733 - f1: 0.7677 - p\n",
      "Epoch 8/50\n",
      "103488/103488 [==============================] - 102s 988us/sample - loss: 808.5546 - acc: 0.7920 - f1: 0.7881 - precision: 0.8075 - recall: 0.7699 - val_loss: 805.8838 - val_acc: 0.7026 - val_f1: 0.6992 - val_precision: 0.7136 - val_recall: 0.6856\n",
      "Epoch 9/50\n",
      "103488/103488 [==============================] - 101s 977us/sample - loss: 802.7662 - acc: 0.8103 - f1: 0.8074 - precision: 0.8234 - recall: 0.7923 - val_loss: 800.1729 - val_acc: 0.6990 - val_f1: 0.6976 - val_precision: 0.7145 - val_recall: 0.6817\n",
      "Epoch 10/50\n",
      "103488/103488 [==============================] - 101s 978us/sample - loss: 797.0021 - acc: 0.8236 - f1: 0.8213 - precision: 0.8358 - recall: 0.8074 - val_loss: 794.4899 - val_acc: 0.6952 - val_f1: 0.6917 - val_precision: 0.7054 - val_recall: 0.6787\n",
      "Epoch 11/50\n",
      " 43968/103488 [===========>..................] - ETA: 56s - loss: 792.8805 - acc: 0.8488 - f1: 0.8470 - precision: 0.8594 - recall: 0.8351 ETA: 57s - loss: 792.9010 - acc: 0.8491 - f1: 0.8474 - precisioWARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_f1` which is not available. Available metrics are: loss,acc,f1,precision,recall,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-3cf8e435d2e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mreduce_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_f1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcooldown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidationX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidationY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_best = ModelCheckpoint('model/best_weights_val_f1.hdf5', save_best_only=True, monitor='val_f1', mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_f1', mode='min', factor=0.2, patience=5, verbose=1, cooldown=3)\n",
    "\n",
    "history = model.fit(trainX, trainY, batch_size=64, validation_data=(validationX, validationY), callbacks=[save_best, reduce_lr], epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 3s 882us/sample - loss: 811.5924 - acc: 0.7197 - f1: 0.7111 - precision: 0.7323 - recall: 0.6918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[811.5923805338541, 0.71966666, 0.7111235, 0.7323402, 0.6918218]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('model/best_weights_val_f1.hdf5')\n",
    "model.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуем ошибки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sequences</th>\n",
       "      <th>padded_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36789</th>\n",
       "      <td>Первое впечатление после просмотра фильма было...</td>\n",
       "      <td>первый впечатление просмотр фильм очень двояки...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1282, 16120, 31807, 1821, 1841, 1445, 98686, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31478</th>\n",
       "      <td>платье очень хорошее, ткань качественная, плот...</td>\n",
       "      <td>платье очень хороший ткань качественный плотны...</td>\n",
       "      <td>1</td>\n",
       "      <td>[28121, 1841, 23365, 29161, 72556, 65635, 9388...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20491</th>\n",
       "      <td>Джинсы класс , заказала на свой обычный s , та...</td>\n",
       "      <td>джинсы класс заказать свой обычный сесть прям ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[19278, 646, 7431, 75309, 1706, 24235, 61828, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8083</th>\n",
       "      <td>Джинсы супер! Беру уже во второй раз.</td>\n",
       "      <td>джинсы супер брать второй раз</td>\n",
       "      <td>1</td>\n",
       "      <td>[19278, 646, 4248, 23976, 1252, 279]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29650</th>\n",
       "      <td>Отличная юбка , оригинально сделанная, не прос...</td>\n",
       "      <td>отличный юбка оригинально сделать не просвечив...</td>\n",
       "      <td>1</td>\n",
       "      <td>[49112, 386, 6911, 4050, 872, 5688, 173, 7413,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "36789  Первое впечатление после просмотра фильма было...   \n",
       "31478  платье очень хорошее, ткань качественная, плот...   \n",
       "20491  Джинсы класс , заказала на свой обычный s , та...   \n",
       "8083               Джинсы супер! Беру уже во второй раз.   \n",
       "29650  Отличная юбка , оригинально сделанная, не прос...   \n",
       "\n",
       "                                            preprocessed  sentiment  \\\n",
       "36789  первый впечатление просмотр фильм очень двояки...          1   \n",
       "31478  платье очень хороший ткань качественный плотны...          1   \n",
       "20491  джинсы класс заказать свой обычный сесть прям ...          1   \n",
       "8083                       джинсы супер брать второй раз          1   \n",
       "29650  отличный юбка оригинально сделать не просвечив...          1   \n",
       "\n",
       "                                               sequences  \\\n",
       "36789  [1282, 16120, 31807, 1821, 1841, 1445, 98686, ...   \n",
       "31478  [28121, 1841, 23365, 29161, 72556, 65635, 9388...   \n",
       "20491  [19278, 646, 7431, 75309, 1706, 24235, 61828, ...   \n",
       "8083                [19278, 646, 4248, 23976, 1252, 279]   \n",
       "29650  [49112, 386, 6911, 4050, 872, 5688, 173, 7413,...   \n",
       "\n",
       "                                        padded_sequences  \n",
       "36789  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "31478  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "20491  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "8083   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "29650  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_explorations = validation[['text', 'preprocessed', 'sentiment', 'sequences', 'padded_sequences']]\n",
    "validation_explorations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def predict(ps):\n",
    "    padded_sequense_array = np.reshape(ps, (1, max_sequence_length))\n",
    "    vector = model.predict(padded_sequense_array).T\n",
    "    vector = np.concatenate(vector, axis=0 )\n",
    "    zipped = np.array(list(zip(outputs_index.keys(), vector.T)))\n",
    "    answer = {x[0]:x[1] for x in zipped}\n",
    "    answer = sorted(answer.items(), key=lambda x: float(operator.itemgetter(1)(x)), reverse=True)[:10]\n",
    "    pred_sentiment = answer[0][0]\n",
    "    return int(pred_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [05:04<00:00, 29.51it/s]\n",
      "D:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sequences</th>\n",
       "      <th>padded_sequences</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36789</th>\n",
       "      <td>Первое впечатление после просмотра фильма было...</td>\n",
       "      <td>первый впечатление просмотр фильм очень двояки...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1282, 16120, 31807, 1821, 1841, 1445, 98686, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31478</th>\n",
       "      <td>платье очень хорошее, ткань качественная, плот...</td>\n",
       "      <td>платье очень хороший ткань качественный плотны...</td>\n",
       "      <td>1</td>\n",
       "      <td>[28121, 1841, 23365, 29161, 72556, 65635, 9388...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20491</th>\n",
       "      <td>Джинсы класс , заказала на свой обычный s , та...</td>\n",
       "      <td>джинсы класс заказать свой обычный сесть прям ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[19278, 646, 7431, 75309, 1706, 24235, 61828, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8083</th>\n",
       "      <td>Джинсы супер! Беру уже во второй раз.</td>\n",
       "      <td>джинсы супер брать второй раз</td>\n",
       "      <td>1</td>\n",
       "      <td>[19278, 646, 4248, 23976, 1252, 279]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29650</th>\n",
       "      <td>Отличная юбка , оригинально сделанная, не прос...</td>\n",
       "      <td>отличный юбка оригинально сделать не просвечив...</td>\n",
       "      <td>1</td>\n",
       "      <td>[49112, 386, 6911, 4050, 872, 5688, 173, 7413,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "36789  Первое впечатление после просмотра фильма было...   \n",
       "31478  платье очень хорошее, ткань качественная, плот...   \n",
       "20491  Джинсы класс , заказала на свой обычный s , та...   \n",
       "8083               Джинсы супер! Беру уже во второй раз.   \n",
       "29650  Отличная юбка , оригинально сделанная, не прос...   \n",
       "\n",
       "                                            preprocessed  sentiment  \\\n",
       "36789  первый впечатление просмотр фильм очень двояки...          1   \n",
       "31478  платье очень хороший ткань качественный плотны...          1   \n",
       "20491  джинсы класс заказать свой обычный сесть прям ...          1   \n",
       "8083                       джинсы супер брать второй раз          1   \n",
       "29650  отличный юбка оригинально сделать не просвечив...          1   \n",
       "\n",
       "                                               sequences  \\\n",
       "36789  [1282, 16120, 31807, 1821, 1841, 1445, 98686, ...   \n",
       "31478  [28121, 1841, 23365, 29161, 72556, 65635, 9388...   \n",
       "20491  [19278, 646, 7431, 75309, 1706, 24235, 61828, ...   \n",
       "8083                [19278, 646, 4248, 23976, 1252, 279]   \n",
       "29650  [49112, 386, 6911, 4050, 872, 5688, 173, 7413,...   \n",
       "\n",
       "                                        padded_sequences  pred_sentiment  \n",
       "36789  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0  \n",
       "31478  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               1  \n",
       "20491  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               1  \n",
       "8083   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               1  \n",
       "29650  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_explorations['pred_sentiment'] = validation_explorations['padded_sequences'].progress_apply(predict)\n",
    "validation_explorations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2625.000000</td>\n",
       "      <td>2625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.108571</td>\n",
       "      <td>-0.110095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.722582</td>\n",
       "      <td>0.738009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment  pred_sentiment\n",
       "count  2625.000000     2625.000000\n",
       "mean     -0.108571       -0.110095\n",
       "std       0.722582        0.738009\n",
       "min      -1.000000       -1.000000\n",
       "25%      -1.000000       -1.000000\n",
       "50%       0.000000        0.000000\n",
       "75%       0.000000        0.000000\n",
       "max       1.000000        1.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_explorations_fails = validation_explorations[validation_explorations['pred_sentiment'] != validation_explorations['sentiment']]\n",
    "validation_explorations_fails.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  Первое впечатление после просмотра фильма было очень двояким. Долгое время я не мог понять, понравился он мне или нет. Как не странно, но чувство аморальности у меня после него не появилось, несмотря на мою достаточно высокую нравственность. Фильм так снят, что появляется ощущение, будто бы это вполне нормально. Лучше стараться смотреть это детище глазами ребёнка или тех неполноценных людей, что его окружают. Ведь каждый из них живет в собственном мире, достаточно далеким от реального, и для них все вокруг - лишь поле для игры.  Назвать этот фильм плохим или хорошим я так и не смогу. В фильме хорошая режиссура, хорошая игра актёров, удивительные пейзажи... Но оценка самой идеи и сюжета фильма остается на индивидуальный вкус каждого. Постарайтесь отбросить все предубеждения и посмотреть на этот фильм невинным детским взглядом.\n",
      "preprocessed text:  первый впечатление просмотр фильм очень двоякий долгий время не мочь понять понравиться нет не странный чувство аморальность не появиться несмотря мой достаточно высокий нравственность фильм снять появляться ощущение это вполне нормальный стараться смотреть этот детище глаз ребёнок тот неполноценный человек окружать каждый жить собственный мир достаточно далёкий реальный вокруг лишь поле игра назвать фильм плохой хороший не смочь фильм хороший режиссура хороший игра актёр удивительный пейзаж оценка самой идея сюжет фильм оставаться индивидуальный вкус каждый постарайтесь отбросить предубеждение посмотреть фильм невинный детский взгляд\n",
      "sequenced text:  ['▁первый ▁впечатление ▁просмотр ▁фильм ▁очень ▁дво я кий ▁долгий ▁время ▁не ▁мо чь ▁понять ▁понра виться ▁нет ▁не ▁странный ▁чувство ▁амора льность ▁не ▁появиться ▁несмотря ▁мой ▁достаточно ▁высокий ▁нрав ственность ▁фильм ▁снять ▁появляться ▁ощущение ▁это ▁вполне ▁нормальный ▁стара ться ▁смотреть ▁этот ▁дети ще ▁глаз ▁ребёнок ▁тот ▁неполноцен ный ▁человек ▁окру жать ▁каждый ▁жить ▁собственный ▁мир ▁достаточно ▁далё кий ▁реальный ▁вокруг ▁лишь ▁поле ▁игра ▁назвать ▁фильм ▁плохой ▁хороший ▁не ▁смо чь ▁фильм ▁хороший ▁режиссура ▁хороший ▁игра ▁актёр ▁удивительный ▁пейзаж ▁оценка ▁самой ▁идея ▁сюжет ▁фильм ▁оставаться ▁индивидуальный ▁вкус ▁каждый ▁поста рай тесь ▁отбросить ▁предубе ждение ▁посмотреть ▁фильм ▁неви нный ▁детский ▁взгляд']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  джинсы ,пришли меньше чем за месяц,на свой 25-26 размер заказала 26,по размеру подошли хорошо ,но вот по росту  короткие ,мой рост 162, обидно,я не люблю короткие джинсы\n",
      "preprocessed text:  джинсы прийти меньше месяц на свой размер заказать по размер подойти но рост короткий мой рост обидный я не любить короткий джинсы\n",
      "sequenced text:  ['▁джин сы ▁прийти ▁меньше ▁месяц ▁на ▁свой ▁размер ▁заказать ▁по ▁размер ▁подойти ▁но ▁рост ▁короткий ▁мой ▁рост ▁оби дный ▁я ▁не ▁любить ▁короткий ▁джин сы']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  \n",
      "По итогам торгов акциями на Казахстанской фондовой бирже (KASE) во вторник значение индекса KASE выросло на 1,58% - с 1198 до 1216,88.\n",
      "\n",
      "Объем сделок с акциями, включенными в представительский список индекса, вырос относительно предыдущего торгового дня в 3,8 раза и составил Т108,7 млн, или $329,1 тыс, сообщает КазТАГ.\n",
      "\n",
      "По данным биржи, в ходе торгов выросли в цене акции Kaz Minerals PLC (+4,9%), АО «Народный банк Казахстана» (+1,9%), АО «Казахтелеком» (+1,4%), АО «Кселл» (+0,7%), АО «KEGOC» (+0,5%), АО «Банк ЦентрКредит» (+0,3%) и АО «КазТрансОйл» (+0,2%).\n",
      "\n",
      "preprocessed text:  итог торг акция казахстанский фондовый бирже ужасный\n",
      "sequenced text:  ['▁итог ▁торг ▁акция ▁казахстанский ▁фон довый ▁бирже ▁ужа сный']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  юбочка пришла, за такие деньги отличная юбка, но мне она совсем не понравилась. юбочка на 42 44 и моя немного просвечивается ткань не плотная.\n",
      "preprocessed text:  юбочка прийти такой деньга отличный юбка не понравиться юбочка немного просвечивается ткань не плотная\n",
      "sequenced text:  ['▁ю бо чка ▁прийти ▁такой ▁день га ▁отличный ▁ю бка ▁не ▁понра виться ▁ю бо чка ▁немного ▁просве чивается ▁ткань ▁не ▁плотная']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Один из самых забавных фильмов, вошедших в программу 'Sex & Fun volume 4'. Всеми признанный 'пластилиновый' гений Пикер создал, конечно не 'Пластилиновую ворону', но постарался на славу.Фильм непосредственно рассказывает о столь далеких временах, когда мужчины не знали, что такое женщины, а женщины в свою очередь не знали, что такое мужчины. Но благодаря рукам Пикера и паре килограммам пластилина они все-таки понимают, зачем Кто-то их создал и выясняют, чем же все-таки мужчины отличаются от женщин.\n",
      "preprocessed text:  самых забавный фильм войти программа весь признать пластилиновый гений пикёр создать не пластилиновый ворона постараться славу фильм непосредственно рассказывать столь далёкий время мужчина не знать такой женщина женщина очередь не знать такой мужчина благодаря рука пикёр пара килограммам пластилин все таки понимать кто то создать выяснять все таки мужчина отличаться женщина\n",
      "sequenced text:  ['▁самых ▁заба вный ▁фильм ▁войти ▁программа ▁весь ▁признать ▁пласти ли новый ▁гений ▁пик ёр ▁создать ▁не ▁пласти ли новый ▁ворона ▁постара ться ▁славу ▁фильм ▁непосредственно ▁рассказывать ▁столь ▁далё кий ▁время ▁мужчина ▁не ▁знать ▁такой ▁женщина ▁женщина ▁очередь ▁не ▁знать ▁такой ▁мужчина ▁благодаря ▁рука ▁пик ёр ▁пара ▁килограм мам ▁пласти лин ▁все ▁таки ▁понимать ▁кто ▁то ▁создать ▁выяс нять ▁все ▁таки ▁мужчина ▁отличаться ▁женщина']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Проснувшись в 5 утра у меня уже вошло в привычку проводить время перед просмотром фильма. Долго перебирала диски в надежде найти то, что еще не смотрела. Даже несколько раз вставляла диск, но все было не то. И вот на глаза попался фильм, который долгое время вызывал внутреннее неприятие. Во-первых, знала что он малобюджетный (всего 250 000$), во-вторых ни одного знакомого актера, да и режиссер не внушал доверия. Короче, раньше тратить время не хотелось. Но в это утро что-то екнуло и решила - для общего развития - включай.Первый минут сорок абсолютно ничего не понимала и меня это бесило. Единственное, что зацепило нестандартное решение антуража, и постоянно перескакивающий кадр с истории на историю, который придавал сюжету динамичность. Постепенно стало интересно - втянулась.И вот прошел час сорок. Я сидела согревая чашку остывшего чая, слушала потрясающий саундтрек и жалела себя. Не смотря на то что закончилась обычная сказка, она заставила задуматься о бессмертной душе. Сама не понимая почему, начала вспоминать какие-то неадекватные решения, ссоры и тот внутренний голос, который подсказывал делать то, или иное...Четко осознала, что в фильме наглядно показан духовный мир, который управляет нашим. Да, это так. Подумайте, ведь мы не всегда делаем то, что хотим. Чаще всего наше решение меняется в последний момент. Кто за этим стоит? Может те, кого называют Инкубами, или Воинами света, а может Сказочница решает исход дела.Резюме такое - точно одно - фильм хороший. Прекрасный режиссер, он же и талантливый композитор (по ходу сравнила его с Клинтом Мэнселем), талантливые красивые актеры, декоратор мегамозг... Его бы создателям бюджет побольше - смотрелось бы куда лучше.Однозначно рекомендую людям с большой фантазией, чистой совестью, и отечественной должностью. Почему? В конце поймете.\n",
      "preprocessed text:  проснуться утро войти привычка проводить время просмотр фильм долго перебирала диск надежда найти то не смотреть несколько вставлять диск не то глаз попасться фильм который долгий время вызывать внутренний неприятие во первый знать малобюджетный ужасный талантливый красивый актёр декоратор мегамозг создатель бюджет побольше смотреться лучше однозначно рекомендовать человек большой фантазия чистый совесть отечественный должность почему конец понять\n",
      "sequenced text:  ['▁прос нуться ▁утро ▁войти ▁привы чка ▁проводить ▁время ▁просмотр ▁фильм ▁долго ▁перебира ла ▁диск ▁надежда ▁найти ▁то ▁не ▁смотреть ▁несколько ▁вста влять ▁диск ▁не ▁то ▁глаз ▁попасть ся ▁фильм ▁который ▁долгий ▁время ▁вызывать ▁внутренний ▁неприятие ▁во ▁первый ▁знать ▁мало бюджет ный ▁ужа сный ▁талантливый ▁красивый ▁актёр ▁декора тор ▁мега моз г ▁создатель ▁бюджет ▁по больше ▁смотре ться ▁лучше ▁однозначно ▁рекомен довать ▁человек ▁большой ▁фантазия ▁чистый ▁совесть ▁отечественный ▁должность ▁почему ▁конец ▁понять']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  К моему глубокому сожалению посылка так и не пришла. Продавец утверждал, что выслал товар. Общались долго. В итоге открыла спор и вернули деньги.\n",
      "preprocessed text:  мой глубокий сожаление посылка не прийти продавец утверждать выслать товар общаться долго итог открыть спор вернуть деньга\n",
      "sequenced text:  ['▁мой ▁глубокий ▁сожаление ▁посы лка ▁не ▁прийти ▁продавец ▁утверждать ▁выслать ▁товар ▁общаться ▁долго ▁итог ▁открыть ▁спор ▁вернуть ▁день га']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  В целом, ничего нового в этой картине не увидишь. Дело в том, что люди в странных масках и с большими кухонными ножами, пытающиеся как можно изворотливей убить кого-нибудь в таком тихом месте, где никого не ждут, тема уже давным-давно избитая, и использовалась много раз.Лично меня привлекло то, что главную героиню здесь играет Тайлер. и, надо признаться, что играет очень хорошо. Пугается очень правдоподобно в отличии от множества актрис, которые снимаются в подобных картинах. В самом начале, нам говорят, что фильм основан на реальных событиях. И это, несомненно, придает дополнительный страх, а точнее чувство тревоги. Ведь, черт возьми, это не выдумки. Вообще, стоит отдать должное, кино держит в напряжении, и порой действительно вздрагиваешь в некоторых моментах. Но, с другой стороны, все очень даже предсказуемо. В любом случае, лично я получил удовольствие от просмотра этого ужастика.\n",
      "preprocessed text:  целом новый картина не увидеть дело том человек странный маска большой кухонный нож пытаться изворотливей убить кто нибудь таком тихий место никто не ждать тема давным давно избить использоваться раз лично привлечь то главный героиня играть тайлер и признаться играть очень хорошо пугаться очень правдоподобно отличии множество актриса которые сниматься подобный картина самом начало нам говорить фильм основать реальный событие это несомненно придавать дополнительный страх точнее чувство тревога ведь чёрт взять это не выдумка вообще стоить отдать должный кино держать напряжение порой действительно вздрагивать некоторый момент но сторона очень предсказуемый любой случай лично получить удовольствие просмотр ужастик\n",
      "sequenced text:  ['▁целом ▁новый ▁картина ▁не ▁увидеть ▁дело ▁том ▁человек ▁странный ▁маска ▁большой ▁кухо нный ▁нож ▁пытаться ▁из ворот ли вей ▁убить ▁кто ▁ни будь ▁таком ▁тихий ▁место ▁никто ▁не ▁ждать ▁тема ▁дав ным ▁давно ▁из бить ▁использоваться ▁раз ▁лично ▁привлечь ▁то ▁главный ▁героиня ▁играть ▁тайлер ▁и ▁признаться ▁играть ▁очень ▁хорошо ▁пуга ться ▁очень ▁правдоподоб но ▁отличи и ▁множество ▁актриса ▁которые ▁сниматься ▁подобный ▁картина ▁самом ▁начало ▁нам ▁говорить ▁фильм ▁основать ▁реальный ▁событие ▁это ▁несомненно ▁прида вать ▁дополнительный ▁страх ▁точнее ▁чувство ▁тревога ▁ведь ▁чёрт ▁взять ▁это ▁не ▁выдум ка ▁вообще ▁стоить ▁отдать ▁долж ный ▁кино ▁держать ▁напряжение ▁порой ▁действительно ▁в здра ги вать ▁некоторый ▁момент ▁но ▁сторона ▁очень ▁предсказу емый ▁любой ▁случай ▁лично ▁получить ▁удовольствие ▁просмотр ▁ужа стик']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  \n",
      "\n",
      "На стадионе ЦСКА при поддержке Управления образования Алматы Общественный фонд \"Добровольное общество \"Милосердие\" провел первый спортивный инклюзивный праздник.\n",
      "\n",
      "preprocessed text:  стадион цска поддержка управление образование алматы общественный фонд добровольный общество милосердие провести первый спортивный инклюзивный праздник\n",
      "sequenced text:  ['▁стадион ▁цска ▁поддержка ▁управление ▁образование ▁алматы ▁общественный ▁фонд ▁доброво льный ▁общество ▁милосердие ▁провести ▁первый ▁спортивный ▁ин клю зив ный ▁праздник']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  заказывала белый цвет, пришел грязно голубой(( я расстроена\n",
      "preprocessed text:  заказывать белый цвет прийти грязно голубой ужасный расстроить\n",
      "sequenced text:  ['▁заказыва ть ▁белый ▁цвет ▁прийти ▁грязно ▁голубой ▁ужа сный ▁рас строить']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  Фильм потряс. Потряс до глубины души. Очень сильная, пронзительная картина.Неужели, неужели все было ИМЕННО так? Фильм - гимн НАСТОЯЩЕЙ дружбе, когда лучше умереть, чем подставить товарищей.Но последний кадр ставит жесткий вопрос: ЗАЧЕМ?ЗАЧЕМ умирали сотни пацанов-героев, а тысячи других возвращались домой калеками? Фильм-провокация, удивляюсь, как его показали по государственному каналу?Наверное, прав чеченец, говорящий, что он здесь за каждый камешек, каждый кустик, каждый кусочек родной земли сражается; что он не убивает, он удаляет опухоль. За что сражались наши ребята? По мне, так только друг за друга, за своих, таких же, как и они, пацанов, кинутых правительством на кровавую бойню.\n",
      "preprocessed text:  фильм потрясти потрясти глубина душа очень сильный пронзительный картина неужели неужели именно так фильм гимн настоящий дружба умереть подставить товарищ но последний кадр ставить жёсткий вопрос зачем зачем умирать сотня пацан герой тысяча других возвращаться домой калека фильм провокация удивляться показать государственный канал наверное право чеченец говорить каждый камешек каждый кустик каждый кусочек родный земля сражаться не убивать удалять опухоль сражаться наш ребята мне друг друга свой такой же они пацан кинуть правительство кровавый бойня\n",
      "sequenced text:  ['▁фильм ▁потря сти ▁потря сти ▁глубина ▁душа ▁очень ▁сильный ▁пронзи тельный ▁картина ▁неу жели ▁неу жели ▁именно ▁так ▁фильм ▁гимн ▁настоящий ▁дружба ▁умереть ▁подста вить ▁товарищ ▁но ▁последний ▁кадр ▁ставить ▁жёсткий ▁вопрос ▁зачем ▁зачем ▁умирать ▁сотня ▁па цан ▁герой ▁тысяча ▁других ▁возвращаться ▁домой ▁кале ка ▁фильм ▁провока ция ▁уди вляться ▁показать ▁государственный ▁канал ▁наверное ▁право ▁чече нец ▁говорить ▁каждый ▁каме шек ▁каждый ▁ку стик ▁каждый ▁кусо чек ▁род ный ▁земля ▁сражаться ▁не ▁убивать ▁удалять ▁опухоль ▁сражаться ▁наш ▁ребята ▁мне ▁друг ▁друга ▁свой ▁такой ▁же ▁они ▁па цан ▁ки нуть ▁правительство ▁кровавый ▁бой ня']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  огромная))) наверное 50й размер\n",
      "preprocessed text:  огромный отличный наверное й размер\n",
      "sequenced text:  ['▁огромный ▁отличный ▁наверное ▁й ▁размер']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  приму в дар улитку-ахатину, желательно помладше. уже и аквариум раздобыла.\n",
      "\n",
      "upd даритель нашелся. спасибо всем, приветствуем Ульяну :)\n",
      "preprocessed text:  принять дар улитку ахатину желательный помладше аквариум раздобыла даритель найтись спасибо всем приветствовать ульян отличный\n",
      "sequenced text:  ['▁принять ▁дар ▁ули тку ▁аха тину ▁жела тельный ▁пом лад ше ▁аквариум ▁раз добы ла ▁дари тель ▁найти сь ▁спасибо ▁всем ▁привет ствовать ▁уль ян ▁отличный']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Я знаю идеального парня . я знаю его номер . я знаю, где он живет . и влюбое время могу ему позвонить и он ответит : \"да, сестренка\"\n",
      "preprocessed text:  знать идеальный парень знать номер знать жить влюбое время мочь позвонить ответить да сестрёнка\n",
      "sequenced text:  ['▁знать ▁идеальный ▁парень ▁знать ▁номер ▁знать ▁жить ▁влю бое ▁время ▁мо чь ▁позво нить ▁ответить ▁да ▁се стр ёнка']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Продавец очень долго отправлял заказ. юбка размера L на ОБ 100 подошла,  но сразу же сломалась молния. заклинило её, потому как она наверно,  самая дешёвая была из всех возможных. на работу она не рассчитана. теперь менять молнию нужно за свой счёт,  а это дополнительные траты. на ощупь юбка приятная, сбился красиво. жаль что не могу её поносить,  пока не заменю молнию!\n",
      "preprocessed text:  продавец очень долго отправлять заказ юбка размер подойти сразу сломаться молния заклинить ее наверно самая дешёвый возможный работа не рассчитать менять молния нужный свой счёт это дополнительный трата ощупь юбка приятный сбился красиво жаль не мочь поносить пока не заменю молния\n",
      "sequenced text:  ['▁продавец ▁очень ▁долго ▁отправлять ▁заказ ▁ю бка ▁размер ▁подойти ▁сразу ▁слома ться ▁молния ▁закли нить ▁ее ▁навер но ▁самая ▁дешё вый ▁возможный ▁работа ▁не ▁рассчитать ▁менять ▁молния ▁нужный ▁свой ▁счёт ▁это ▁дополнительный ▁тра та ▁ощу пь ▁ю бка ▁приятный ▁сби лся ▁красиво ▁жаль ▁не ▁мо чь ▁по носить ▁пока ▁не ▁замен ю ▁молния']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  заказываю второй раз. пришли во время, но с браком и цвет не тот, что на фото. расстроилась, открыла спор, Ali обещал вернуть деньги. в целом продавец хороший! буду заказывать еще, надеюсь, что брака не будет!\n",
      "preprocessed text:  заказывать второй раз прийти время брак цвет не тот фото расстроиться открыть спор обещать вернуть деньга целом продавец хороший буду заказывать еще надеяться брак не будет\n",
      "sequenced text:  ['▁заказыва ть ▁второй ▁раз ▁прийти ▁время ▁брак ▁цвет ▁не ▁тот ▁фото ▁расстрои ться ▁открыть ▁спор ▁обе щать ▁вернуть ▁день га ▁целом ▁продавец ▁хороший ▁буду ▁заказыва ть ▁еще ▁надеяться ▁брак ▁не ▁будет']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  На ОБ 104 см заказала ХХХL, помогли отзывы покупателей. На шортах нет этикетки с информацией о составе ткани.\n",
      "preprocessed text:  см заказать х помочь отзыв покупатель шортах нет этикетка информация состав ткань\n",
      "sequenced text:  ['▁см ▁заказать ▁х ▁помочь ▁отзыв ▁покупатель ▁шор тах ▁нет ▁этикет ка ▁информация ▁состав ▁ткань']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  Смотрел картину. Поставлена, разыграна - да, но не оправдана такая растяжка на два с лишним часа. Нет там столько событий. Именно растянутость в основном и уменьшила позитивное впечатление.\n",
      "preprocessed text:  смотреть картина поставить разыграна да не оправдать такой растяжка лишний час нет столько событие именно растянутость основном уменьшить позитивный впечатление\n",
      "sequenced text:  ['▁смотреть ▁картина ▁поставить ▁разыгра на ▁да ▁не ▁оправдать ▁такой ▁растя жка ▁лишний ▁час ▁нет ▁столько ▁событие ▁именно ▁растя ну тость ▁основном ▁уменьшить ▁пози тивный ▁впечатление']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Это конечно жесть) Индия имеет талант рулит))\n",
      "preprocessed text:  это жесть отличный индия иметь талант рулить отличный\n",
      "sequenced text:  ['▁это ▁же сть ▁отличный ▁индия ▁иметь ▁талант ▁ру лить ▁отличный']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  я часто покупаю вещи из флиса, и этот показался каким-то на ощупь особо синтетическим. Хотяб обычно флис-это самая приятная ткань.\n",
      "preprocessed text:  часто покупать вещь флиса показаться какой то ощупь особо синтетический хотяб обычно флис это самая приятный ткань\n",
      "sequenced text:  ['▁часто ▁покупать ▁вещь ▁ф лиса ▁показаться ▁какой ▁то ▁ощу пь ▁особо ▁синте тический ▁хотя б ▁обычно ▁ф лис ▁это ▁самая ▁приятный ▁ткань']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Есть фраза: Судить о политике может каждый, а делать её – единицы. Фильм является наглядным тому примером. Тут и не искушенному человеку понятно, что данное творение является заказным, рассчитанным на подрыв российской идеологии и политики «Кремля». Если не обращать внимания на национальность прототипов, то можно сказать, что получился не плохой боевик, с нормальными спецэффектами. Жаль, что в столь пропагандистском фильме снялись такие замечательные актёры как Энди Гарсия и Вэл Килмер, честно – не ожидал. Мне, человеку, относящемуся к поколению восьмидесятых, не впервой наблюдать антисоветские (антироссийские) картины, как раньше они разрушали мозг нашему поколению, так и теперь продолжают заниматься тем же, их просто нельзя воспринимать всерьёз. Очень плохо, что такие фильмы и этот в частности будут смотреть наши дети, с их доверчивой и не окрепшей психикой, что, отнюдь, не приведет к росту их патриотизма. Фильм, однозначно – в топку, или смотреть без озвучки, что тоже вариант.Как боевику ставлю 8, за идею фильма 0 (противно) и того в среднем 4 из 10\n",
      "preprocessed text:  фраза судить политика каждый делать единица фильм являться наглядный тот пример не искушённый человек понятный данное творение являться заказной рассчитанным подрыв российский идеология политика кремль не обращать внимание национальность прототип сказать получиться не плохой боевик нормальный спецэффектами жаль столь пропагандистский фильм сняться такой замечательный актёр энди гарсия вэл килмер честно не ожидать мне человек относящемуся поколение восьмидесятых не впервой наблюдать антисоветский ужасный среднем ужасный\n",
      "sequenced text:  ['▁фраза ▁судить ▁политика ▁каждый ▁делать ▁единица ▁фильм ▁являться ▁нагля дный ▁тот ▁пример ▁не ▁иску шённый ▁человек ▁поня тный ▁данное ▁творение ▁являться ▁заказ ной ▁рассчита нным ▁подрыв ▁российский ▁идеология ▁политика ▁кремль ▁не ▁обращать ▁внимание ▁национальность ▁прототип ▁сказать ▁получи ться ▁не ▁плохой ▁боевик ▁нормальный ▁спецэффе ктами ▁жаль ▁столь ▁пропагандист ский ▁фильм ▁сняться ▁такой ▁замечательный ▁актёр ▁энди ▁гарсия ▁вэл ▁кил мер ▁честно ▁не ▁ожидать ▁мне ▁человек ▁относя щемуся ▁поколение ▁восьмидесятых ▁не ▁впер вой ▁наблюдать ▁анти советский ▁ужа сный ▁среднем ▁ужа сный']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  Давай со мной за звездами 🌟😍😌\n",
      "Давай наберем их гроздями😇✨\n",
      "preprocessed text:  давать мной звезда давать наберем гроздь\n",
      "sequenced text:  ['▁давать ▁мной ▁звезда ▁давать ▁набе рем ▁гроз дь']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Заказ не пришел. Деньги вернули\n",
      "preprocessed text:  заказ не прийти деньга вернуть\n",
      "sequenced text:  ['▁заказ ▁не ▁прийти ▁день га ▁вернуть']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  «Три могилы» перекликаются с недавней картиной «Предложение» по сценарию и с музыкой Ника Кейва. Что Австралия 19-го века, что Америка, век 21-й – та же беспросветная глушь, те же люди с уродливыми душами и та же благодатная почва для «жёсткой жести».Люди с веками не меняются. Стремление к низким поступкам, лжи и изменам сидит у нас в генах. Но рано или поздно наступает deadline, приходится отвечать за свои поступки и собираться в дорогу, чтобы предстать перед Создателем. Вот только с каким багажом?\n",
      "preprocessed text:  три могила перекликаются недавний картина предложение сценарий музыка ник кейва австралия го век америка век й тот беспросветный глушь тот человек уродливый душа тот благодатный почва жёсткий жесть человек век не меняться стремление низкий поступок ложь изменам сидеть ген рано поздно наступать приходиться отвечать свой поступок собираться дорога предстать создатель какой багаж\n",
      "sequenced text:  ['▁три ▁могила ▁перекли каются ▁недав ний ▁картина ▁предложение ▁сценарий ▁музыка ▁ник ▁кей ва ▁австралия ▁го ▁век ▁америка ▁век ▁й ▁тот ▁бес про свет ный ▁глу шь ▁тот ▁человек ▁урод ливый ▁душа ▁тот ▁благода тный ▁почва ▁жёсткий ▁же сть ▁человек ▁век ▁не ▁меняться ▁стремление ▁низкий ▁поступок ▁ложь ▁изме нам ▁сидеть ▁ген ▁рано ▁поздно ▁наступать ▁приходи ться ▁отвечать ▁свой ▁поступок ▁собираться ▁дорога ▁предста ть ▁создатель ▁какой ▁багаж']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  вроде бы по описанию, но короткая и рукава тоже короткие , неудобно то что резинка внизу куртки еще\n",
      "preprocessed text:  вроде описание короткий рукава короткий неудобный резинка внизу куртка\n",
      "sequenced text:  ['▁вроде ▁описание ▁короткий ▁рукава ▁короткий ▁неудоб ный ▁рези нка ▁внизу ▁кур тка']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Ярчайший представитель европейского хоррора (итальянский Джордж Ромеро) Лучио Фульчи представляет мистический ужастик Седьмые Врата ада или на американский манер - The Beyond. Несмотря на мистику, без зомби здесь не обошлось (такова была мода и требования прокатчиков), ибо Фульчи и сделал себе имя на оживших мертвецах. Сам сюжет разворачивается в США - в Луизиане. Место действия - старый отель, построенный на вратах ада. В фильме огромное внимание уделяется разъеданию и терзанию человеческой плоти (причем весь фильм, что то происходит с глазами жертв) - достаточно рвотно и страшно. Особого внимания заслуживает музыкальное оформление. Интересный факт - из-за ограниченности бюджета, для изображения зомби Фульчи нанял местных бомжей, которые работали за выпивку и бухали между дублями.\n",
      "preprocessed text:  яркий представитель европейский хоррор ужасный достаточно рвотно страшный особый внимание заслуживать музыкальный оформление интересный факт из за ограниченность бюджет изображение зомби фульчи нанять местный бомж которые работать выпивка бухать дубль\n",
      "sequenced text:  ['▁яркий ▁представитель ▁европейский ▁хоррор ▁ужа сный ▁достаточно ▁рво тно ▁страшный ▁особый ▁внимание ▁заслу живать ▁музыкальный ▁оформление ▁интересный ▁факт ▁из ▁за ▁ограниче нность ▁бюджет ▁изображение ▁зомби ▁фу льчи ▁нанять ▁местный ▁бом ж ▁которые ▁работать ▁выпи вка ▁буха ть ▁дубль']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  на мои параметры оказалось огромным\n",
      "preprocessed text:  мой параметр оказаться огромный\n",
      "sequenced text:  ['▁мой ▁параметр ▁оказаться ▁огромный']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Скажу сразу - я фанат Смешариков! Очень большой фанат! Поэтому как только узнал о полном метре, пошел не задумываясь (в 3D)... И не прогадал!Сюжет. Этот мультфильм можно назвать приквелом сериала. В нем идет рассказ о том, как в стране Смешариков происходит знаменательное событие - всем известные Крош и Ежик находят. ..телевизор, и насмотревшись сериалов про супергероя Люсьена (Копатыча), всем гуртом отправляются на помощь герою в таинственный и неизвестный Большой Мир! Там они попадают в круговорот событий, который навсегда изменит их привычный мир! Сюжет очень интересный и захватывающий. Также в мультике много отсылок к разным фильмам: 'Титаник', 'Форсаж', что-то, на мой взгляд, похоже на 'Миссия невыполнима' и т.д. (+)Анимация и 3D. Приятно видеть красивую, сочную и яркую картинку. Вдвойне приятно знать, что это дело рук наших аниматоров. И 3D тут очень даже к месту: с первых кадров ты попадаешь то в зеленый мир Смешариков, а затем в серый и высокий, но тем не менее красивый Большой Город. (+) Саундтрек. Он хорош. Музыку и песни в этом мультике было приятно слушать, особо понравились песни 'Спасибо тебе, прохожий' и «Ниточка». Они точно подставлены под действия в мультфильме. (+)   Актеры. Озвучка теми же актерами, что и в сериале. И как же мне нравится тот факт, что один актер может озвучить нескольких персонажей (например Михаил Черняк озвучил Копатыча, Пина, Лосяша). (+)   Вывод. 'Смешарики. Начало' - отличный мультик для всей семьи, который можно смотреть снова и снова! Надеюсь у полного метра будет продолжение!10 из 10А как по другому?- Я знал, знал что мы все сумасшедшие, но не до такой же степени!- Когда у тебя благородная цель, тебе все помогает: и море, и небо, все, все, все!Ты что, не видел как Люсьен три дня назад в одиночку переплыл океан?- Еще отстреливаться приходилось. (с)\n",
      "preprocessed text:  сказать сразу фанат смешариков очень большой фанат поэтому узнать полный метр пойти не задумываться ужасный\n",
      "sequenced text:  ['▁сказать ▁сразу ▁фанат ▁смеша риков ▁очень ▁большой ▁фанат ▁поэтому ▁узнать ▁полный ▁метр ▁пойти ▁не ▁задумы ваться ▁ужа сный']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  да артэк оххх как хочеться к тебе!!!!!!!!!!!!!!!!!в ту же палпту в речной и одиннадцатый отряд с этими же вожатыми\n",
      "preprocessed text:  артэк ох хочеться тебе в тот палпту речной одиннадцатый отряд этот вожатыми\n",
      "sequenced text:  ['▁арт эк ▁ох ▁хо че ться ▁тебе ▁в ▁тот ▁пал п ту ▁речной ▁одиннадцатый ▁отряд ▁этот ▁вожа тыми']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Как я заметил, люди разделились на два лагеря - одни плюются и называют фильм полной парашей, вторые же утверждают, что это элитнейший артхаус с глубокими идеями. Я считаю, что обе эти позиции не верны (даже если предположить, что слонофилы просто траллируют). И вот почему.Плохим фильм не является, поскольку это, можно сказать, 'народная' комедия. Под народом я подразумеваю наше поколение, которое попало на момент распространения интернет технологий в России. Как известно, Слон получил признание на анонимных досках, а в последствии, вместе с интернет культурой в целом, стал достоянием общественности через соцсети. Но что примечательно, он выдержал испытание обыдлением и остался одним из немногочисленных мемов, которые остались не сильно замараны интеллектуальным большинством. При этом, как я уже сказал, это неплохая комедия с харизматичными и талантливыми актерами. Фильм, по сути, это чудесная импровизация. Причем смешно каждый раз, хотя я конечно почти наизусть знаю все отличные истории Пахома.В фильме наблюдается определенная динамика. Если в начале что-то еще более или менее осмысленное, то к концу начинается безумие. Вообще, последняя треть фильма мне показалась неудачной, да и смешных моментов там почти нет.С другой стороны, никакого глубокого смысла тут нет и быть не может. Это, в общем-то, любительская работа, которая держится исключительно на таланте угарных актеров. Сама Баскова, как показал 'За Маркса', особым талантом не отличается и снимает полную ахинею при попытке создать что-то поприличнее. Я встречал удивительные интерпретации этого фильма и отдельных его элементов, отсылки чуть ли не к Канту и Шопенгауэру, даже евангелический подтекст. Это, по моему мнению, не так, и фильм абсолютно пуст в плане смыслового содержания, это чистая импровизация на тему сидения в карцере.Сам я, кстати, посмотрел Слоника относительно поздно, причем меня уговорил знакомый (в обмен он должен был посмотреть художественный фильм 'Выб$@%ки'). Посмотрел я с удовольствием, поскольку было смешно. Чего-то особо отвратного я тоже не увидел, есть картины с куда более шокирующим и омерзительным содержанием. Но и чего-то шедеврального от этой поделки тоже ждать нельзя. Однако культурное значение Слона огромно, и это неотъемлемая часть ушедшей эпохи двухтысячных (как братки и приставка Денди - девяностых).\n",
      "preprocessed text:  заметить человек разделиться лагерь один плеваться называть фильм полный парашей второй утверждать это элитнейший артхаус глубокий идея считать оба позиция не верный ужасный\n",
      "sequenced text:  ['▁заметить ▁человек ▁раздели ться ▁лагерь ▁один ▁пле ваться ▁называть ▁фильм ▁полный ▁пара шей ▁второй ▁утверждать ▁это ▁элит нейший ▁арт хаус ▁глубокий ▁идея ▁считать ▁оба ▁позиция ▁не ▁верный ▁ужа сный']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  В 4:00 утра город идеален: без людей, а только с пустыми улицами, с прохладным воздухом и полной луной.\n",
      "preprocessed text:  утро город идеален человек пустой улица прохладный воздух полный луной\n",
      "sequenced text:  ['▁утро ▁город ▁иде ален ▁человек ▁пустой ▁улица ▁прохлад ный ▁воздух ▁полный ▁луной']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  Товар пришел быстро, 14.08 заказала, пришел 28.08 трек отслеживался. Что касается самого кордигана. Запах есть. Размер... мой размер 42-44, кардиган оказался велик в плечах, в подмышечной зоне. Был бы поменьше было бы лучше. Носить мне его теперь только на даче. \n",
      "preprocessed text:  товар прийти быстро заказать прийти трек отслеживался касаться самого кордигана запах быть размер размер кардиган оказаться большой плечах подмышечный зона поменьше лучше носить дача\n",
      "sequenced text:  ['▁товар ▁прийти ▁быстро ▁заказать ▁прийти ▁трек ▁отслежива лся ▁каса ться ▁самого ▁корди гана ▁запах ▁быть ▁размер ▁размер ▁карди ган ▁оказаться ▁большой ▁плечах ▁под мыше чный ▁зона ▁по меньше ▁лучше ▁носить ▁дача']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  воскресное утро ! самое дело отправиться на велопробежку !\n",
      "preprocessed text:  воскресный утро самое дело отправиться велопробежку\n",
      "sequenced text:  ['▁воскрес ный ▁утро ▁самое ▁дело ▁отправиться ▁вело про бе жку']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Ткань слегка тонковата, но всё же достаточно теплая. Рисунок пропечатан слабо и нечётко, нитки торчат из всех швов, пришлось подрезать  и закреплять, но на зиму в качестве домашней кофты более чем)\n",
      "preprocessed text:  ткань слегка тонковата достаточно тёплый рисунок пропечатать слабо нечетко нитка торчать шов прийтись подрезать закреплять зима качество домашний кофта отличный\n",
      "sequenced text:  ['▁ткань ▁слегка ▁тон кова та ▁достаточно ▁тёплый ▁рисунок ▁про печа тать ▁слабо ▁не чет ко ▁ни тка ▁тор чать ▁шов ▁прийти сь ▁под реза ть ▁закрепля ть ▁зима ▁качество ▁домашний ▁ко фта ▁отличный']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Очень понравились колготки, красиво смотрятся на ногах, качество мягкое и приятное, на вид прочные. Но с этим продавцом открыла спор по другому товару, т.к. пришли рваные колготки( Поэтому кому как повезет....\n",
      "preprocessed text:  очень понравиться колготки красиво смотреться нога качество мягкий приятный вид прочный этот продавец открыть спор другому товар т к прийти рваный колготки ужасный поэтому кто повезти\n",
      "sequenced text:  ['▁очень ▁понра виться ▁кол го тки ▁красиво ▁смотре ться ▁нога ▁качество ▁мягкий ▁приятный ▁вид ▁прочный ▁этот ▁продавец ▁открыть ▁спор ▁другому ▁товар ▁т ▁к ▁прийти ▁рва ный ▁кол го тки ▁ужа сный ▁поэтому ▁кто ▁пове зти']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  куртка не такая воздушная как на фото\n",
      "preprocessed text:  куртка не такой воздушный фото\n",
      "sequenced text:  ['▁кур тка ▁не ▁такой ▁воздушный ▁фото']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  и снова Дацик!! зверьь! хоть и смотрится \"неспортивно\" но дух бойца в нём превелик!\n",
      "preprocessed text:  снова дацик зверьь смотреться неспортивно дух боец нем превелик\n",
      "sequenced text:  ['▁снова ▁да цик ▁зверь ь ▁смотре ться ▁не спор тивно ▁дух ▁боец ▁нем ▁пре вели к']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  ЕБРР выделил деньги на развитие в РК женского предпринимательства Вчера, 14:11 В ForteBank рассказали, на каких условиях можно получить финансирование на развитие бизнеса\n",
      "\n",
      "preprocessed text:  ебрр выделить деньга развитие рк женский предпринимательство вчера рассказать какой условие получить финансирование развитие бизнес\n",
      "sequenced text:  ['▁е бр р ▁выделить ▁день га ▁развитие ▁рк ▁женский ▁предпринима тельство ▁вчера ▁рассказать ▁какой ▁условие ▁получить ▁финансирование ▁развитие ▁бизнес']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Я сделала это!Была на глубине 27метров красного моря!\n",
      "preprocessed text:  сделать это была глубина метр красный море\n",
      "sequenced text:  ['▁сделать ▁это ▁была ▁глубина ▁метр ▁красный ▁море']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Валюшка)***\n",
      "preprocessed text:  валюшка отличный\n",
      "sequenced text:  ['▁валю шка ▁отличный']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  \n",
      "В ведомстве с участием Министерства по инвестициям и развитию РК, представителей НПП «Атамекен», «КазАвтоПром», «АКАБ» (Ассоциация казахстанского автобизнеса), автопроизводителей и ТОО Оператора РОП состоялось заседание рабочей группы по вопросам реализации расширенных обязательств производителей (импортеров). На заседании был рассмотрен вопрос о выработке условий Программы по внедрению механизма вышедших из эксплуатации транспортных средств (ВЭТС).\n",
      "Запуск данного проекта позволит казахстанским владельцам авто за сдачу старого автомобиля получать 48 тысяч тенге либо 150 тысяч тенге. В пилотной версии проекта, предложенной рабочей группой, автовладелец сдает в пункты сбора ТОО Оператора РОП транспортное средство категории М1 (легковой автомобиль, массой, не превышающей 3,5 тонн или семи посадочных мест) на дальнейшую утилизацию, а взамен получает денежную компенсацию по одной из двух комплектаций автомобиля: полной комплектации 150 тысяч тенге и автомобили не на ходу (обязательно наличие кузова, дверей, двигателя, коробки передач) - 48 тысяч тенге.\n",
      "Условия приема и порядок выплат будет определен Оператором РОП. Прием отработанных транспортных средств будет осуществляться  ТОО «Оператор РОП» http://www.recycle.kz/ в 17 городах Казахстана.\n",
      "Разработчики программы утилизации ВЭТС, считают, что данный проект позволит сократить количество неэкологичных и потенциально небезопасных транспортных средств. По предварительным оценкам ТОО «Оператор РОП», до конца 2016 года ожидается собрать порядка 10 тысяч ВЭТС.\n",
      "Предполагается, что накопленные объемы ВЭТС в дальнейшем будут поступать на данный шредерный комплекс.\n",
      "Необходимо отметить, что программа утилизации ВЭТС также будет иметь большой социальный и экономический эффекты в виде стимулирования предпринимательства и создания новых рабочих мест.\n",
      "\n",
      "preprocessed text:  ведомство участие министерство инвестиция развитие рк представитель нпп атамекен казавтопром акаб ужасный тысяча тенге условие приём порядок выплата определить оператор роп приём отработать транспортный средство осуществляться тоо оператор роп город казахстан разработчик программа утилизация вэтс считать данный проект позволить сократить количество неэкологичных потенциально небезопасный транспортный средство предварительный оценка тоо оператор роп конец год ожидаться собрать порядка тысяча вэтс предполагаться накопленные объём вэтс дальнейшем будут поступать данный шредерный комплекс необходимый отметить программа утилизация вэтс также иметь большой социальный экономический эффект вид стимулирование предпринимательство создание новый рабочий место\n",
      "sequenced text:  ['▁ведомство ▁участие ▁министерство ▁инвести ция ▁развитие ▁рк ▁представитель ▁нпп ▁ата ме кен ▁каза вто пром ▁ака б ▁ужа сный ▁тысяча ▁тенге ▁условие ▁приём ▁порядок ▁выплата ▁определить ▁оператор ▁роп ▁приём ▁от работать ▁транспортный ▁средство ▁осуществляться ▁тоо ▁оператор ▁роп ▁город ▁казахстан ▁разработчик ▁программа ▁ути лизация ▁в этс ▁считать ▁данный ▁проект ▁позволить ▁сократить ▁количество ▁не эко логи чных ▁потенциально ▁небезопас ный ▁транспортный ▁средство ▁предварительный ▁оценка ▁тоо ▁оператор ▁роп ▁конец ▁год ▁ожида ться ▁собрать ▁порядка ▁тысяча ▁в этс ▁предполага ться ▁нако пленные ▁объём ▁в этс ▁дальнейшем ▁будут ▁поступать ▁данный ▁шре дер ный ▁комплекс ▁необходимый ▁отметить ▁программа ▁ути лизация ▁в этс ▁также ▁иметь ▁большой ▁социальный ▁экономический ▁эффект ▁вид ▁стиму лирование ▁предпринима тельство ▁создание ▁новый ▁рабочий ▁место']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  заказ отправили 26.08, пришел в Новосибирск 16.09.  Качество для такой цены подходящее. Размерной сетке соответствует.\n",
      "preprocessed text:  заказ отправить прийти новосибирск качество цена подходить размерный сетка соответствовать\n",
      "sequenced text:  ['▁заказ ▁отправить ▁прийти ▁новосибирск ▁качество ▁цена ▁подходить ▁размер ный ▁сетка ▁соответствовать']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  ХВАТИТ ГАРУСНЫХ СТАТУСОВ!!!!!ЛЕТО!!!)))ПОРА НА ОТДЫХ!!!!! РАССЛАБЬСЯ!!!!!))))))\n",
      "preprocessed text:  хватить гарусный статус лето отличный пора отдых расслабься отличный\n",
      "sequenced text:  ['▁хва тить ▁га рус ный ▁статус ▁лето ▁отличный ▁пора ▁отдых ▁рассла бь ся ▁отличный']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  это было страстное поздравление))))))\n",
      "preprocessed text:  это страстной поздравление отличный\n",
      "sequenced text:  ['▁это ▁страстной ▁поздра вление ▁отличный']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Выздровлю повторим натюрморт!!!!))))\n",
      "preprocessed text:  выздровлю повторим натюрморт отличный\n",
      "sequenced text:  ['▁вы зд ров лю ▁повтори м ▁натюрморт ▁отличный']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  Довольно неплохое продолжение ужасающего сериала по роману Клайва Баркера. В фильме также присутствует чувство жанра и большое количество крови. Слегка огорчил вид ада. Можно было бы столько показать, но нет. Вместо гиены огненной и чёртиков в красных пижамах с трезубцами в фильме нам показали жуткий и мрачный лабиринт, в котором не так то просто найти выход. А так в общем фильм неплохой. За не очень страшный образ подземного царства8 из 10\n",
      "preprocessed text:  довольно неплохой продолжение ужасать сериал роман клайв баркера фильм также присутствовать чувство жанр большой количество кровь слегка огорчить вид ад столько показать нет вместо гиена огненной чёртик красный пижамах трезубец фильм нам показать жуткий мрачный лабиринт котором не просто найти выход общем фильм неплохой не очень страшный образ подземный царство отличный\n",
      "sequenced text:  ['▁довольно ▁неплохой ▁продолжение ▁ужаса ть ▁сериал ▁роман ▁клайв ▁бар кера ▁фильм ▁также ▁присутствовать ▁чувство ▁жанр ▁большой ▁количество ▁кровь ▁слегка ▁огор чить ▁вид ▁ад ▁столько ▁показать ▁нет ▁вместо ▁ги ена ▁огненной ▁чёр тик ▁красный ▁пи жа мах ▁тре зу бец ▁фильм ▁нам ▁показать ▁жут кий ▁мрачный ▁лабиринт ▁котором ▁не ▁просто ▁найти ▁выход ▁общем ▁фильм ▁неплохой ▁не ▁очень ▁страшный ▁образ ▁подземный ▁царство ▁отличный']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Товар не пришёл, но продавец вернул деньги\n",
      "preprocessed text:  товар не прийти продавец вернуть деньга\n",
      "sequenced text:  ['▁товар ▁не ▁прийти ▁продавец ▁вернуть ▁день га']\n",
      "predicted: -1, true label: 1\n",
      "\n",
      "\n",
      "text:  Да так... Если без шуток, то просто главный герой убил 7 миллиардов человек. Потому что ему с ними было как-то скучновато. Общественный строй какой-то странный. Хотелось домой. Всё правильно рассчитал.'Всё по плану!' (с) Вот и очередная инкарнация верной боевой подруги сразу в наличии. Везунчик. А ведь мог наш гений сыска остаться человеком. Мог. Тем более, прямым текстом предлагали. Идти во власть - и пахать. Коль считаешь, что вокруг много неверного, неестественного - постарайся исправить, чёрт возьми!! Не бойся, родной, остаться в истории чем-то вроде Горбачёва. Эти люди таковы во многом благодаря твоим благим намерениям. Но знаете ли, Маленький Принц - это совершенно не отсюда. Тут у нас налицо животворящий гибрид Люцифера с Тарасом Бульбой. В общем, для тех, кто понимает, 'эта штука посильнее Фауста' (с). До продюсеров Первого, правда, сей факт дошёл с некоторым опозданием. Сразу надо, товарищи, сериал до конца досматривать.Да, оценку чуть снижаю из-за довольно-таки многочисленных технических ляпов. \n",
      "preprocessed text:  так шутка просто главный герой убить миллиард человек ними как то скучноватый общественный строй какой то странный хотеться домой правильно рассчитать весь план ужасный продюсер первый правда сей факт дойти некоторый опоздание сразу надо товарищ сериал конец досматривать да оценка снижать из за довольно таки многочисленный технический ляп\n",
      "sequenced text:  ['▁так ▁шутка ▁просто ▁главный ▁герой ▁убить ▁миллиард ▁человек ▁ними ▁как ▁то ▁ску ч нова тый ▁общественный ▁строй ▁какой ▁то ▁странный ▁хоте ться ▁домой ▁правильно ▁рассчитать ▁весь ▁план ▁ужа сный ▁продюсер ▁первый ▁правда ▁сей ▁факт ▁дойти ▁некоторый ▁опо здание ▁сразу ▁надо ▁товарищ ▁сериал ▁конец ▁до сматри вать ▁да ▁оценка ▁сни жать ▁из ▁за ▁довольно ▁таки ▁многочисленный ▁технический ▁ля п']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  по размеру подошли но очень короткие это минус\n",
      "preprocessed text:  размер подойти очень короткий это минус\n",
      "sequenced text:  ['▁размер ▁подойти ▁очень ▁короткий ▁это ▁минус']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n",
      "text:  Фильм, который затягивает с первых минут, и ты не можешь оторваться до самого его конца. Приятно то, что не было моментов, где какая-то сцена 'приелась', то есть сюжет раскрывался так, что тебе уставать не приходится - не быстро и не медленно. Он, кстати, такой, что зритель удивится в его крутых поворотах, что является изюминкой фильма о агенте ЦРУ.Игра актёров - превосходная, музыкальное сопровождение - на высоте. Единственное, что не понравилось, так это эффект мигания в начальных титрах - не приятно смотреть на экран. В общем, 'Рекрут' - динамичный эффектный фильм, оставляющий впечатления после просмотра.\n",
      "preprocessed text:  фильм который затягивать первый минута не мочь оторваться самого конец приятный то не момент какой то сцена приесться сюжет раскрываться так тебе уставать не приходиться не быстро не медленно он кстати такой зритель удивится крутой поворот являться изюминка фильм агент цру игра актёр превосходный музыкальный сопровождение высота единственный не понравиться это эффект мигание начальный титр не приятный смотреть экран общем рекрут динамичный эффектный фильм оставлять впечатление просмотр\n",
      "sequenced text:  ['▁фильм ▁который ▁затяги вать ▁первый ▁минута ▁не ▁мо чь ▁отор ваться ▁самого ▁конец ▁приятный ▁то ▁не ▁момент ▁какой ▁то ▁сцена ▁прие сть ся ▁сюжет ▁раскры ваться ▁так ▁тебе ▁уста вать ▁не ▁приходи ться ▁не ▁быстро ▁не ▁медленно ▁он ▁кстати ▁такой ▁зритель ▁уди вится ▁крутой ▁поворот ▁являться ▁изю минка ▁фильм ▁агент ▁цру ▁игра ▁актёр ▁превосход ный ▁музыкальный ▁сопровождение ▁высота ▁единственный ▁не ▁понра виться ▁это ▁эффект ▁мига ние ▁начальный ▁ти тр ▁не ▁приятный ▁смотреть ▁экран ▁общем ▁рек рут ▁динами чный ▁эффект ный ▁фильм ▁оставлять ▁впечатление ▁просмотр']\n",
      "predicted: 0, true label: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "#для демонстрации ограничимся 50 примерами - в реальном проекте необходимо анализировать больше ошибок\n",
    "for i, row in itertools.islice(validation_explorations_fails.iterrows(), 50):\n",
    "    print('text: ', row['text'])\n",
    "    print('preprocessed text: ', row['preprocessed'])\n",
    "    print('sequenced text: ', tokenizer.sequences_to_texts([row['sequences']]))\n",
    "    print(f'predicted: {(row[\"pred_sentiment\"])}, true label: {(row[\"sentiment\"])}')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2625/2625 [00:00<00:00, 62485.73it/s]\n",
      "D:\\SoftwareProjects\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "def get_fail_group(row):\n",
    "    return f\"({row['sentiment']})-({row['pred_sentiment']})\"\n",
    "\n",
    "validation_explorations_fails['fail_group'] = validation_explorations_fails.progress_apply(get_fail_group, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_explorations_fails['fail_group'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'sentiment'}>], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(9, 4))\n",
    "validation_explorations_fails.hist(column='pred_sentiment', ax=ax[0])\n",
    "validation_explorations_fails.hist(column='sentiment', ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.80      0.80      0.80      1000\n",
      "     neutral       0.62      0.61      0.61      1000\n",
      "    negative       0.74      0.74      0.74      1000\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      3000\n",
      "   macro avg       0.72      0.72      0.72      3000\n",
      "weighted avg       0.72      0.72      0.72      3000\n",
      " samples avg       0.72      0.72      0.72      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm\n",
    "testY_pred = model.predict(testX)\n",
    "testY_pred = np.argmax(testY_pred, axis=1)\n",
    "testY_pred = np.apply_along_axis(lambda x: to_categorical(x, num_classes=len(outputs_index)), 0, testY_pred)\n",
    "\n",
    "print(skm.classification_report(testY, testY_pred, target_names=['positive', 'neutral', 'negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы и комментарии\n",
    "\n",
    "Нейросеть редко допускает грубые ошибки, когда истинный лейбл является прямопротивоположным предсказанному.\n",
    "Частая ошибка нейросети заключается в присваивании нейтральных лейблов.\n",
    "\n",
    "Некоторые мысли насчет улучшения качества сети:\n",
    "* Система может показать лучший результат, если использовать ансамбль из нескольких нейронный сетей, натренированных на работу с текстами определенной длины, например, до 20 слов, до 50 слов и до 100 слов.\n",
    "* В реальных сообщениях человек может иронично назвать непонравившийся фильм \"шедевром\" в кавычках - возможно не стоит избавляться от всех символов.\n",
    "* Имеет смысл сети оставлять запятые, чтобы было понятно, к чему относится то или прилагательное.\n",
    "* Т.к. сеть имеет некоторый перекос в ошибках с нейтральными примерами, имеет смысл немного перебалансировать обучающий набор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold валидация\n",
    "\n",
    "Финальная проверка - доказательство того, что точность модели не привязана к подобранным данным.\n",
    "В настоящем примере в силу ограниченностиы вычислительных возможностей не провожу."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X, Y = get_arrayed_data(df.sample(frac=1))\n",
    "\n",
    "k = 10\n",
    "total = len(X)\n",
    "step = int(total/k)\n",
    "story = []\n",
    "evaluations = []\n",
    "for i in range(0, k):\n",
    "    print(f'{i+1}/{k}')       \n",
    "    inp = Input((max_sequence_length,))\n",
    "    \n",
    "    embedding_layer = Embedding(len(tokenizer.word_index) + 1, 100,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_sequence_length,\n",
    "                    embeddings_regularizer=regularizers.l2(0.001),\n",
    "                    trainable=True)\n",
    "    \n",
    "    x = embedding_layer(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu',\n",
    "               kernel_regularizer=regularizers.l1(0.001),\n",
    "               bias_regularizer=regularizers.l1(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = AveragePooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    x = LSTM(64, activity_regularizer=regularizers.l1(0.0001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    out = Dense(trainY.shape[1], activation='softmax')(x)\n",
    "    inner_model = Model(inp, out)\n",
    "\n",
    "    inner_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', f1, precision, recall])\n",
    "    \n",
    "    weights_path = f'kfold_{i+1}_best_weights_val_f1.hdf5'\n",
    "    save_best = ModelCheckpoint(weights_path, save_best_only=True, monitor='val_f1', mode='max')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_f1', mode='min', factor=0.2, patience=5, verbose=1, cooldown=3)\n",
    "\n",
    "    history = inner_model.fit(trainX, trainY, batch_size=32, validation_data=(validationX, validationY), callbacks=[save_best, reduce_lr], epochs=50, verbose=1)\n",
    "    story.append(history)\n",
    "    \n",
    "    inner_model.load_weights(weights_path)\n",
    "    evaluation_result = inner_model.evaluate(testX, testY)\n",
    "    evaluations.append(evaluation_result)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i, h in enumerate(story):\n",
    "    plot_history(h.history, f'iteration {i+1}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f1_scores = [eval_[1] for eval_ in evaluations]\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "print(f'Средний показатель F1-метрики k-fold валидации при k={k}: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Экспорт модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model/model-config.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(\"model/model-weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
